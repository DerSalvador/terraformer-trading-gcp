resource "google_compute_instance_template" "tfer--gke-private-cluster-3-default-pool-bfffbc48" {
  can_ip_forward = "false"

  disk {
    auto_delete  = "true"
    boot         = "true"
    device_name  = "persistent-disk-0"
    disk_size_gb = "100"
    disk_type    = "pd-balanced"

    labels = {
      goog-k8s-cluster-location = "europe-west1-b"
      goog-k8s-cluster-name     = "private-cluster-3"
      goog-k8s-node-pool-name   = "default-pool"
    }

    mode         = "READ_WRITE"
    source_image = "projects/gke-node-images/global/images/gke-1277-gke1056000-cos-105-17412-226-23-c-pre"
    type         = "PERSISTENT"
  }

  labels = {
    goog-k8s-cluster-location = "europe-west1-b"
    goog-k8s-cluster-name     = "private-cluster-3"
    goog-k8s-node-pool-name   = "default-pool"
  }

  machine_type = "e2-highmem-2"

  metadata = {
    cluster-location           = "europe-west1-b"
    cluster-name               = "private-cluster-3"
    cluster-uid                = "cfa1fee59baa4e558e841277c9031181ed60cd6d46ca444290b533540ef36313"
    configure-sh               = "#!/usr/bin/env bash\n\n# Copyright 2016 The Kubernetes Authors.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Due to the GCE custom metadata size limit, we split the entire script into two\n# files configure.sh and configure-helper.sh. The functionality of downloading\n# kubernetes configuration, manifests, docker images, and binary files are\n# put in configure.sh, which is uploaded via GCE custom metadata.\n\nset -o errexit\nset -o nounset\nset -o pipefail\n\n### Hardcoded constants\nDEFAULT_EXTERNAL_IMAGE_AUTH_PROVIDER_VERSION=\"v0.0.2-gke.4\"\nDEFAULT_EXTERNAL_IMAGE_AUTH_PROVIDER_SHA512_AMD64=\"156058e5b3994cba91c23831774033e0d505d6d8b80f43541ef6af91b320fd9dfaabe42ec8a8887b51d87104c2b57e1eb895649d681575ffc80dd9aee8e563db\"\nDEFAULT_EXTERNAL_IMAGE_AUTH_PROVIDER_SHA512_ARM64=\"1aa3b0bea10a9755231989ffc150cbfa770f1d96932db7535473f7bfeb1108bafdae80202ae738d59495982512e716ff7366d5f414d0e76dd50519f98611f9ab\"\nDEFAULT_CNI_VERSION='v1.0.1-gke.7'\nDEFAULT_CNI_HASH_LINUX_AMD64='de6ff2e5e71e11f80e4f26cb269310c44a4e873d1912624efd588026a7896f35e8a8ced771e486cfa3b6a9d7260418ee24c8d1d175eb7b7f91729796108bba33'\nDEFAULT_CNI_HASH_LINUX_ARM64='3c29abe3bcc2aa467950cab937a7654c9c150ea02995d14c70767718c1abcdb7bda9f7802f3654a653003cb47551eb5088d329550b57bd7c268c793b4dcba7b4'\nDEFAULT_NPD_VERSION='v0.8.13-57-gc3c5389'\nDEFAULT_NPD_HASH_AMD64='2cb0f1610adb5d8d3c077d8ce7a65fb4066f419e82c3ed4ce72a7c4b337bcef7ab9e53d006d97bea70acd980565e2df80466858e6b5291cb1d10587bf0fb9d6c'\nDEFAULT_NPD_HASH_ARM64='e049d37298cbcb3479b3fdc2927ca169fdbe7661dc5c6b1f7cd8f9fb66634eb1c12858155b40f32f86262ebca1171061ce92a520668ce898f89936c668214207'\nNPD_CUSTOM_PLUGINS_VERSION=\"v1.0.9\"\nNPD_CUSTOM_PLUGINS_TAR_HASH=\"14136cd8c71d2a89fb5b6d7f648bab787d95e2b2b39ee960cf6e544259249ae7abc97599eae5ce173a11ea48333d1f59e55da4cb3c718281e253c46ff6883a36\"\nDEFAULT_CRICTL_VERSION='v1.26.1-gke.1'\nDEFAULT_CRICTL_AMD64_SHA512='f5deaa4fd8f1e24b06e3f502da818e847d4216585908b1f58faf214d4453ca13167f6ba87ded6400ddab2aaa4550877daec86b803da27264ead689dfdaf4d4e4'\nDEFAULT_CRICTL_ARM64_SHA512='b1fe6d5545a8c25c0bea9f86d99704b6f1ed406a4969ec7ef15bf059b32dfd108e593c8dc85e1a64db4eff56617ef0afcb32152c70cc670ea8a24a3b3805be96'\nDEFAULT_MOUNTER_ROOTFS_VERSION='v1.0.0'\nDEFAULT_MOUNTER_ROOTFS_TAR_AMD64_SHA512='631330b7fa911d67e400b1d014df65a7763667d4afd4ecefe11a4a89dc9b8be626e5610d53b536c255a3ab488408ab2da8a0699d9fdad280cb3aa24bc2f30ab0'\nDEFAULT_MOUNTER_ROOTFS_TAR_ARM64_SHA512='83cf9ab7961627359654131abd2d4c4b72875d395c50cda9e417149b2eb53b784dfe5c2f744ddbccfe516e36dd64c716d69d161d8bc8b4f42a9207fe676d0bc1'\n\nRIPTIDE_FUSE_VERSION=\"v0.162.0\"\nRIPTIDE_FUSE_ARM64_SHA512='470a23eba2bc291d628db7607f522c5eb3ce06a07f8c9ca60908db01f832f2935bdcf14565d58cceb3d1326689f1e7853e8ab9fa3c435fa2b50142152d5337fa'\nRIPTIDE_FUSE_BIN_ARM64_SHA512='c46d39902602652b348d596fb2fc79d4fc64f136e52ddc7b35acb8e2d178f4f24fda8168ef0cfd6cae2e949f664be31af3ef9fb15c8b490f15cb16f972c90386'\nRIPTIDE_FUSE_AMD64_SHA512='a4b50d81dd17381a033e64008a4bab82db5629414a44fc27cd0f033bbd4d3922b67c6a68e2c2051aa173bd16bd70fb6d2e33abea05f44d24b2025b07d5a48863'\nRIPTIDE_FUSE_BIN_AMD64_SHA512='dc09d14cea2b69a08c4ae80c56acd65cc6dc7831aec09f933ce62fbfbc0b30f6a755282fe683c85578769641d1d753e88d43417519dafd5745681ad52b0848bd'\n\nRIPTIDE_SNAPSHOTTER_VERSION=\"v1.27-0\"\nRIPTIDE_SNAPSHOTTER_SHA512='3b8b7f688de9a59cf2ba154f7583770fd6551d79eaaf428eb1af41c812579f18b4d365f7b4b0a9b5c24e9dc035314e6ea95417a29903abfa54d01624349974c9'\nRIPTIDE_SNAPSHOTTER_BIN_ARM64_SHA512='4ca5927b5456bd742ae81d65d41908410313d5e49a2b1da61e9226939f94c43e6509aadc0f7d3a0c750ee5e3b5fc665400fc20eb1298bd125b3418c6a323ee32'\nRIPTIDE_SNAPSHOTTER_BIN_AMD64_SHA512='636f718817d323f70930122669f5af3faf92a6b6864a72c062ef7eb1b331d743781f20ff8f979527f23cc8289f165b489ec81977d0ccf7ca067c7d74e4b0acc4'\n\nAUTH_PROVIDER_GCP_VERSION=\"v0.0.2-gke.4\"\nAUTH_PROVIDER_GCP_HASH_LINUX_AMD64=\"156058e5b3994cba91c23831774033e0d505d6d8b80f43541ef6af91b320fd9dfaabe42ec8a8887b51d87104c2b57e1eb895649d681575ffc80dd9aee8e563db\"\nAUTH_PROVIDER_GCP_HASH_LINUX_ARM64=\"1aa3b0bea10a9755231989ffc150cbfa770f1d96932db7535473f7bfeb1108bafdae80202ae738d59495982512e716ff7366d5f414d0e76dd50519f98611f9ab\"\n\n###\n\n# Backend endpoints (configurable for TPC).\n# May be overridden when kube-env is sourced.\n#\n# NOTE: Endpoints should behave exactly like a GDU (Google Default Universe)\n# endpoint. E.g., An alternative `STORAGE_ENDPOINT` must have the same buckets\n# and paths as the `storage.googleapis.com` that this script depends on.\nSTORAGE_ENDPOINT=\"${STORAGE_ENDPOINT:-https://storage.googleapis.com}\"\nPGA_ENDPOINT=\"${PGA_ENDPOINT:-private.googleapis.com}\"\nKUBE_DOCKER_REGISTRY=\"${KUBE_DOCKER_REGISTRY:-gke.gcr.io}\"\n\n# Whether to configure private google access or not (defaults to true).\n# May be overridden when kube-env is sourced.\nCONFIGURE_PGA=\"${CONFIGURE_PGA:-true}\"\n\nAUTH_PROVIDER_GCP_VERSION=\"v0.0.2-gke.4\"\nAUTH_PROVIDER_GCP_HASH_LINUX_AMD64=\"156058e5b3994cba91c23831774033e0d505d6d8b80f43541ef6af91b320fd9dfaabe42ec8a8887b51d87104c2b57e1eb895649d681575ffc80dd9aee8e563db\"\nAUTH_PROVIDER_GCP_HASH_LINUX_ARM64=\"1aa3b0bea10a9755231989ffc150cbfa770f1d96932db7535473f7bfeb1108bafdae80202ae738d59495982512e716ff7366d5f414d0e76dd50519f98611f9ab\"\nAUTH_PROVIDER_GCP_LINUX_BIN_DIR=\"/home/kubernetes/bin\"\n\n# Standard curl flags.\nCURL_FLAGS='--fail --silent --show-error --retry 5 --retry-delay 3 --connect-timeout 10 --retry-connrefused'\n\n# This version needs to be the same as in gke/cluster/gce/gci/configure-helper.sh\nGKE_CONTAINERD_INFRA_CONTAINER=\"pause:3.8@sha256:880e63f94b145e46f1b1082bb71b85e21f16b99b180b9996407d61240ceb9830\"\n\nfunction set-broken-motd {\n  cat > /etc/motd <<EOF\nBroken (or in progress) Kubernetes node setup! Check the cluster initialization status\nusing the following commands.\n\nMaster instance:\n  - sudo systemctl status kube-master-installation\n  - sudo systemctl status kube-master-configuration\n\nNode instance:\n  - sudo systemctl status kube-node-installation\n  - sudo systemctl status kube-node-configuration\nEOF\n}\n\n# A function that fetches a GCE metadata value and echoes it out.\n# Args:\n#   $1 : URL path after /computeMetadata/v1/ (without heading slash).\n#   $2 : An optional default value to echo out if the fetch fails.\n#\n# NOTE: this function is duplicated in configure-helper.sh, any changes here\n# should be duplicated there as well.\nfunction get-metadata-value {\n  local default=\"${2:-}\"\n\n  local status\n  # shellcheck disable=SC2086\n  curl ${CURL_FLAGS} \\\n    -H 'Metadata-Flavor: Google' \\\n    \"http://metadata/computeMetadata/v1/${1}\" \\\n  || status=\"$?\"\n  status=\"${status:-0}\"\n\n  if [[ \"${status}\" -eq 0 || -z \"${default}\" ]]; then\n    return \"${status}\"\n  else\n    echo \"${default}\"\n  fi\n}\n\n# A function to fetch kube-env from GCE metadata server\n# or using hurl on the master if available\nfunction download-kube-env {\n  (\n    umask 077\n    local kube_env_path=\"/tmp/kube-env.yaml\"\n    if [[ \"$(is-master)\" == \"true\" \u0026\u0026 $(use-hurl) = \"true\" ]]; then\n      local kube_env_path=\"${KUBE_HOME}/kube-env.yaml\"\n      download-kube-env-hurl \"${kube_env_path}\"\n    else\n      local meta_path=\"http://metadata.google.internal/computeMetadata/v1/instance/attributes/kube-env\"\n      echo \"Downloading kube-env via GCE metadata from ${meta_path} to ${kube_env_path}\"\n      # shellcheck disable=SC2086\n      retry-forever 10 curl ${CURL_FLAGS} \\\n        -H \"X-Google-Metadata-Request: True\" \\\n        -o \"${kube_env_path}\" \\\n        \"${meta_path}\"\n    fi\n\n    # Convert the yaml format file into a shell-style file.\n    eval \"$(python3 -c '''\nimport pipes,sys,yaml\nitems = yaml.load(sys.stdin, Loader=yaml.BaseLoader).items()\nfor k, v in items:\n    print(\"readonly {var}={value}\".format(var=k, value=pipes.quote(str(v))))\n''' < \"${kube_env_path}\" > \"${KUBE_HOME}/kube-env\")\"\n\n    # Leave kube-env if we are a master\n    if [[ \"$(is-master)\" != \"true\" ]]; then\n      rm -f \"${kube_env_path}\"\n    fi\n  )\n}\n\n# A function to pull kube-env from HMS using hurl\nfunction download-kube-env-hurl {\n  local -r kube_env_path=\"$1\"\n  local -r endpoint=$(get-metadata-value \"instance/attributes/gke-api-endpoint\")\n  local -r kube_env_hms_path=$(get-metadata-value \"instance/attributes/kube-env-path\")\n\n  echo \"Downloading kube-env via hurl from ${kube_env_hms_path} to ${kube_env_path}\"\n  retry-forever 30 ${KUBE_HOME}/bin/hurl --hms_address $endpoint \\\n    --dst \"${kube_env_path}\" \\\n    \"${kube_env_hms_path}\"\n  chmod 600 \"${kube_env_path}\"\n}\n\nfunction download-kubelet-config {\n  local -r dest=\"$1\"\n  echo \"Downloading Kubelet config file, if it exists\"\n  # Fetch kubelet config file from GCE metadata server.\n  (\n    umask 077\n    local -r tmp_kubelet_config=\"/tmp/kubelet-config.yaml\"\n    # shellcheck disable=SC2086\n    retry-forever 10 curl ${CURL_FLAGS} \\\n      -H \"X-Google-Metadata-Request: True\" \\\n      -o \"${tmp_kubelet_config}\" \\\n      http://metadata.google.internal/computeMetadata/v1/instance/attributes/kubelet-config\n    # only write to the final location if curl succeeds\n    mv \"${tmp_kubelet_config}\" \"${dest}\"\n  )\n}\n\n# A function to pull kube-master-certs from HMS using hurl\nfunction download-kube-master-certs-hurl {\n  local -r endpoint=$(get-metadata-value \"instance/attributes/gke-api-endpoint\")\n  local -r tmp_kube_master_certs_path=\"/tmp/kube-master-certs.yaml\"\n  local -r kube_master_certs_path=\"${KUBE_HOME}/kube-master-certs\"\n  local -r kube_master_certs_hms_path=$(get-metadata-value \"instance/attributes/kube-master-certs-path\")\n\n  echo \"Downloading kube-master-certs via hurl from ${kube_master_certs_hms_path} to ${tmp_kube_master_certs_path}\"\n  retry-forever 30 ${KUBE_HOME}/bin/hurl --hms_address $endpoint \\\n    --dst \"${tmp_kube_master_certs_path}\" \\\n    \"${kube_master_certs_hms_path}\"\n\n  # Convert the yaml format file into a shell-style file.\n  eval \"$(python3 -c '''\nimport pipes,sys,yaml\nitems = yaml.load(sys.stdin, Loader=yaml.BaseLoader).items()\nfor k, v in items:\n    print(\"readonly {var}={value}\".format(var=k, value=pipes.quote(str(v))))\n''' < \"${tmp_kube_master_certs_path}\" > \"${kube_master_certs_path}\")\"\n\n  # Remove the temp certs and strip perms for other users\n  rm -f \"${tmp_kube_master_certs_path}\"\n  chmod 600 \"${kube_master_certs_path}\"\n}\n\nfunction validate-hash {\n  local -r file=\"$1\"\n  local -r expected=\"$2\"\n\n  actual_sha1=$(sha1sum \"${file}\" | awk '{ print $1 }') || true\n  actual_sha512=$(sha512sum \"${file}\" | awk '{ print $1 }') || true\n  if [[ \"${actual_sha1}\" != \"${expected}\" ]] \u0026\u0026 [[ \"${actual_sha512}\" != \"${expected}\" ]]; then\n    echo \"== ${file} corrupted, sha1 ${actual_sha1}/sha512 ${actual_sha512} doesn't match expected ${expected} ==\"\n    return 1\n  fi\n}\n\n# Get default service account credentials of the VM.\nGCE_METADATA_INTERNAL=\"http://metadata.google.internal/computeMetadata/v1/instance\"\nfunction get-credentials {\n  # shellcheck disable=SC2086\n  curl ${CURL_FLAGS} \\\n    -H \"Metadata-Flavor: Google\" \\\n    \"${GCE_METADATA_INTERNAL}/service-accounts/default/token\" \\\n  | python3 -c 'import sys; import json; print(json.loads(sys.stdin.read())[\"access_token\"])'\n}\n\nfunction valid-storage-scope {\n  # shellcheck disable=SC2086\n  curl ${CURL_FLAGS} \\\n    -H \"Metadata-Flavor: Google\" \\\n    \"${GCE_METADATA_INTERNAL}/service-accounts/default/scopes\" \\\n  | grep -E \"auth/devstorage|auth/cloud-platform\"\n}\n\n# Determine if this node is a master using metadata\nfunction is-master {\n  local -r is_master_val=${KUBERNETES_MASTER:-$(get-metadata-value \"instance/attributes/is-master-node\")}\n  local result=\"false\"\n  if [[ ${is_master_val:-} == \"true\" ]]; then\n    result=\"true\"\n  fi\n  echo $result\n}\n\n# A function that returns \"true\" if hurl should be used, \"false\" otherwise.\nfunction use-hurl {\n  local -r enable_hms_read=${ENABLE_HMS_READ:-$(get-metadata-value \"instance/attributes/enable_hms_read\")}\n  local result=\"false\"\n\n  if [[ -f \"${KUBE_HOME}/bin/hurl\" \u0026\u0026 \"${enable_hms_read}\" == \"true\" ]]; then\n    result=\"true\"\n  fi\n  echo $result\n}\n\n# Retry a download until we get it. Takes a hash and a set of URLs.\n#\n# $1 is the sha512/sha1 hash of the URL. Can be \"\" if the sha512/sha1 hash is unknown.\n# $2+ are the URLs to download.\nfunction download-or-bust {\n  local -r hash=\"$1\"\n  shift 1\n\n  while true; do\n    for url in \"$@\"; do\n      local file=\"${url##*/}\"\n      rm -f \"${file}\"\n      # if the url belongs to GCS API we should use oauth2_token in the headers if the VM service account has storage scopes\n      local curl_headers=\"\"\n\n      if [[ \"$url\" =~ ^${STORAGE_ENDPOINT}/.* ]] ; then\n        local canUseCredentials=0\n\n        echo \"Getting the scope of service account configured for VM.\"\n        if ! valid-storage-scope ; then\n          canUseCredentials=1\n          # this behavior is preserved for backward compatibility. We want to fail fast if SA is not available\n          # and try to download without SA if scope does not exist on SA\n          echo \"No service account or service account without storage scope. Attempt to download without service account token.\"\n        fi\n\n        if [[ \"${canUseCredentials}\" == \"0\" ]] ; then\n          echo \"Getting the service account access token configured for VM.\"\n          local access_token=\"\";\n          if access_token=$(get-credentials); then\n            echo \"Service account access token is received. Downloading ${url} using this token.\"\n          else\n            echo \"Cannot get a service account token. Exiting.\"\n            exit 1\n          fi\n\n          curl_headers=${access_token:+Authorization: Bearer \"${access_token}\"}\n        fi\n      fi\n      if ! curl ${curl_headers:+-H \"${curl_headers}\"} -f --ipv4 -Lo \"${file}\" --connect-timeout 20 --retry 6 --retry-delay 10 --retry-connrefused \"${url}\"; then\n        echo \"== Failed to download ${url}. Retrying. ==\"\n      elif [[ -n \"${hash}\" ]] \u0026\u0026 ! validate-hash \"${file}\" \"${hash}\"; then\n        echo \"== Hash validation of ${url} failed. Retrying. ==\"\n      else\n        if [[ -n \"${hash}\" ]]; then\n          echo \"== Downloaded ${url} (HASH = ${hash}) ==\"\n        else\n          echo \"== Downloaded ${url} ==\"\n        fi\n        return\n      fi\n    done\n  done\n}\n\nfunction record-preload-info {\n  echo \"$1,$2\" >> \"${KUBE_HOME}/preload_info\"\n  echo \"Recording preload info for ${1} ${2}\"\n}\n\nfunction is-preloaded {\n  local -r key=$1\n  local -r value=$2\n  grep -qs \"${key},${value}\" \"${KUBE_HOME}/preload_info\"\n}\n\nfunction is-ubuntu {\n  [[ -f \"/etc/os-release\" \u0026\u0026 $(grep ^NAME= /etc/os-release) == 'NAME=\"Ubuntu\"' ]]\n}\n\nfunction split-commas {\n  echo -e \"${1//,/'\\n'}\"\n}\n\nfunction remount-flexvolume-directory {\n  local -r flexvolume_plugin_dir=$1\n  mkdir -p \"$flexvolume_plugin_dir\"\n  mount --bind \"$flexvolume_plugin_dir\" \"$flexvolume_plugin_dir\"\n  mount -o remount,exec \"$flexvolume_plugin_dir\"\n}\n\nfunction install-gci-mounter-tools {\n  CONTAINERIZED_MOUNTER_HOME=\"${KUBE_HOME}/containerized_mounter\"\n  if [[ -n \"${MOUNTER_ROOTFS_VERSION:-}\" ]]; then\n      local -r mounter_rootfs_version=\"${MOUNTER_ROOTFS_VERSION}\"\n      local -r mounter_rootfs_tar_sha=\"${MOUNTER_ROOTFS_TAR_SHA512}\"\n  else\n    local -r mounter_rootfs_version=\"${DEFAULT_MOUNTER_ROOTFS_VERSION}\"\n    case \"${HOST_PLATFORM}/${HOST_ARCH}\" in\n      linux/amd64)\n        local -r mounter_rootfs_tar_sha=\"${DEFAULT_MOUNTER_ROOTFS_TAR_AMD64_SHA512}\"\n        ;;\n      linux/arm64)\n        local -r mounter_rootfs_tar_sha=\"${DEFAULT_MOUNTER_ROOTFS_TAR_ARM64_SHA512}\"\n        ;;\n      *)\n        echo \"Unrecognized version and platform/arch combination:\"\n        echo \"$mounter_rootfs_version $HOST_PLATFORM/$HOST_ARCH\"\n        echo \"Set MOUNTER_ROOTFS_VERSION and MOUNTER_ROOTFS_TAR_SHA512 to overwrite\"\n        exit 1\n        ;;\n    esac\n  fi\n\n  if is-preloaded \"mounter\" \"${mounter_rootfs_tar_sha}\"; then\n    echo \"mounter is preloaded.\"\n    return\n  fi\n\n  echo \"Downloading gci mounter tools.\"\n  mkdir -p \"${CONTAINERIZED_MOUNTER_HOME}\"\n  chmod a+x \"${CONTAINERIZED_MOUNTER_HOME}\"\n\n  # Copy the mounter binary downloaded with the k8s binaries tar file\n  cp \"${KUBE_HOME}/kubernetes/server/bin/mounter\" \"${CONTAINERIZED_MOUNTER_HOME}/mounter\"\n  chmod a+x \"${CONTAINERIZED_MOUNTER_HOME}/mounter\"\n  # Download the debian rootfs required for the mounter container\n  mkdir -p \"${CONTAINERIZED_MOUNTER_HOME}/rootfs\"\n  local -r mounter_rootfs_tar=\"containerized-mounter-${mounter_rootfs_version}_${HOST_PLATFORM}_${HOST_ARCH}.tar.gz\"\n  download-or-bust \"${mounter_rootfs_tar_sha}\" \"${STORAGE_ENDPOINT}/gke-release/containerized-mounter/${mounter_rootfs_version}/${mounter_rootfs_tar}\"\n  mv \"${KUBE_HOME}/${mounter_rootfs_tar}\" \"/tmp/${mounter_rootfs_tar}\"\n  tar xzf \"/tmp/${mounter_rootfs_tar}\" -C \"${CONTAINERIZED_MOUNTER_HOME}/rootfs\"\n  rm \"/tmp/${mounter_rootfs_tar}\"\n  mkdir -p \"${CONTAINERIZED_MOUNTER_HOME}/rootfs/var/lib/kubelet\"\n\n  record-preload-info \"mounter\" \"${mounter_rootfs_tar_sha}\"\n}\n\nfunction docker-installed {\n    if systemctl cat docker.service \u0026> /dev/null ; then\n        return 0\n    else\n        return 1\n    fi\n}\n\nfunction disable_aufs() {\n  # disable aufs module if aufs is loaded\n  if lsmod | grep \"aufs\" \u0026> /dev/null ; then\n    sudo modprobe -r aufs\n  fi\n}\n\nfunction detect_mtu {\n  local MTU=1460\n  if [[ \"${DETECT_MTU:-}\" == \"true\" ]];then\n    local default_nic=$(ip route get 8.8.8.8 | sed -nr \"s/.*dev ([^\\ ]+).*/\\1/p\")\n    if [ -f \"/sys/class/net/$default_nic/mtu\" ]; then\n      MTU=$(cat /sys/class/net/$default_nic/mtu)\n    fi\n  fi\n  echo $MTU\n}\n\n# This function cofigures docker. It has no conditional logic.\n# It will restart docker service so new settings will be picked up.\n# This method cannot be preloaded as the boot disk changes will not be persistet thru the reboots.\nfunction assemble-docker-flags {\n  # log the contents of the /etc/docker/daemon.json if already exists\n  if [ -f /etc/docker/daemon.json ]; then\n    echo \"Contents of the old docker config\"\n    cat /etc/docker/daemon.json\n  fi\n\n  disable_aufs\n\n  # COS and Ubuntu have different docker options configured as command line arguments.\n  # Use systemctl show docker to see the full list of options.\n  # When configuring Docker options you can use daemon.json or command line arguments\n  # The same option cannot be configured by both, even if it is a list option and can be repeated in the command line multiple times.\n  # This is why we are not simply configuring everything in daemon.json.\n\n  local MTU=\"$(detect_mtu)\"\n\n  # options to be set on COS, registry-mirror is pre-configured on COS\n  local os_specific_options=\"\\\"live-restore\\\": true,\\\n   \\\"storage-driver\\\": \\\"overlay2\\\",\\\n   \\\"mtu\\\": ${MTU},\"\n\n  if is-ubuntu; then\n    # Ubuntu already have everthing set\n    os_specific_options=\"\"\n  fi\n\n  # Important setting: set docker0 cidr to private ip address range to avoid conflict with cbr0 cidr range (\"bip\": \"169.254.123.1/24\")\n  cat > /etc/docker/daemon.json <<EOF\n{\n  \"pidfile\": \"/var/run/docker.pid\",\n  \"iptables\": false,\n  \"ip-masq\": false,\n  \"log-level\": \"warn\",\n  \"bip\": \"169.254.123.1/24\",\n  \"log-driver\": \"json-file\",\n  ${os_specific_options}\n  \"log-opts\": {\n      \"max-size\": \"10m\",\n      \"max-file\": \"5\"\n  }\n}\nEOF\n\n  # Ensure TasksMax is sufficient for docker.\n  # (https://github.com/kubernetes/kubernetes/issues/51977)\n  echo \"Extend the docker.service configuration to set a higher pids limit\"\n  mkdir -p /etc/systemd/system/docker.service.d\n  cat <<EOF >/etc/systemd/system/docker.service.d/01tasksmax.conf\n[Service]\nTasksMax=infinity\nEOF\n\n  # Do not move to the daemon.json file for backward compatibility.\n  # Command line and config file options cannot be both defined and custoemr customization may break.\n  # insecure-registry setting was inherited from the past, see b/203231428. Keeping for backward compatibility.\n  echo \"DOCKER_OPTS=\\\"--registry-mirror=https://mirror.gcr.io --insecure-registry 10.0.0.0/8\\\"\" > /etc/default/docker\n\n  systemctl daemon-reload\n  echo \"Docker command line and configuration are updated. Restart docker to pick it up\"\n  systemctl restart docker\n}\n\n# Install node problem detector binary.\nfunction install-node-problem-detector {\n  if [[ -n \"${NODE_PROBLEM_DETECTOR_VERSION:-}\" ]]; then\n      local -r npd_version=\"${NODE_PROBLEM_DETECTOR_VERSION}\"\n      local -r npd_hash=\"${NODE_PROBLEM_DETECTOR_TAR_HASH}\"\n  else\n      local -r npd_version=\"${DEFAULT_NPD_VERSION}\"\n      case \"${HOST_PLATFORM}/${HOST_ARCH}\" in\n        linux/amd64)\n          local -r npd_hash=\"${DEFAULT_NPD_HASH_AMD64}\"\n          ;;\n        linux/arm64)\n          local -r npd_hash=\"${DEFAULT_NPD_HASH_ARM64}\"\n          ;;\n        # no other architectures are supported currently.\n        # Assumption is that this script only runs on linux,\n        # see cluster/gce/windows/k8s-node-setup.psm1 for windows\n        # https://github.com/kubernetes/node-problem-detector/releases/\n        *)\n          echo \"Unrecognized version and platform/arch combination:\"\n          echo \"$DEFAULT_NPD_VERSION $HOST_PLATFORM/$HOST_ARCH\"\n          echo \"Set NODE_PROBLEM_DETECTOR_VERSION and NODE_PROBLEM_DETECTOR_TAR_HASH to overwrite\"\n          exit 1\n          ;;\n      esac\n  fi\n  local -r npd_tar=\"node-problem-detector-${npd_version}-${HOST_PLATFORM}_${HOST_ARCH}.tar.gz\"\n\n  if is-preloaded \"${npd_tar}\" \"${npd_hash}\"; then\n    echo \"${npd_tar} is preloaded.\"\n    return\n  fi\n\n  echo \"Downloading ${npd_tar}.\"\n  local -r npd_release_path=\"${NODE_PROBLEM_DETECTOR_RELEASE_PATH:-${STORAGE_ENDPOINT}/gke-release}\"\n  download-or-bust \"${npd_hash}\" \"${npd_release_path}/node-problem-detector/${npd_tar}\"\n  local -r npd_dir=\"${KUBE_HOME}/node-problem-detector\"\n  mkdir -p \"${npd_dir}\"\n  tar xzf \"${KUBE_HOME}/${npd_tar}\" -C \"${npd_dir}\" --overwrite\n  mv \"${npd_dir}/bin\"/* \"${KUBE_BIN}\"\n  chmod a+x \"${KUBE_BIN}/node-problem-detector\"\n  rmdir \"${npd_dir}/bin\"\n  rm -f \"${KUBE_HOME}/${npd_tar}\"\n\n  record-preload-info \"${npd_tar}\" \"${npd_hash}\"\n}\n\n# Install node problem detector custom plugins.\nfunction install-npd-custom-plugins {\n  local -r version=\"${NPD_CUSTOM_PLUGINS_VERSION}\"\n  local -r hash=\"${NPD_CUSTOM_PLUGINS_TAR_HASH}\"\n  local -r tar=\"npd-custom-plugins-${version}.tar.gz\"\n\n  if is-preloaded \"${tar}\" \"${hash}\"; then\n    echo \"${tar} is preloaded.\"\n    return\n  fi\n\n  echo \"Downloading ${tar}.\"\n  download-or-bust \"${hash}\" \"${STORAGE_ENDPOINT}/gke-release/npd-custom-plugins/${version}/${tar}\"\n  local -r dir=\"${KUBE_HOME}/npd-custom-plugins\"\n  mkdir -p \"${dir}\"\n  tar xzf \"${KUBE_HOME}/${tar}\" -C \"${dir}\" --overwrite\n  rm -f \"${KUBE_HOME}/${tar}\"\n\n  record-preload-info \"${tar}\" \"${hash}\"\n}\n\nfunction install-cni-binaries {\n  local -r cni_version=${CNI_VERSION:-$DEFAULT_CNI_VERSION}\n  if [[ -n \"${CNI_VERSION:-}\" ]]; then\n    local -r cni_hash=\"${CNI_HASH:-}\"\n  else\n    local -r cni_hash_var=\"DEFAULT_CNI_HASH_${HOST_PLATFORM^^}_${HOST_ARCH^^}\"\n    local -r cni_hash=\"${!cni_hash_var}\"\n  fi\n\n  local -r cni_tar=\"cni-plugins-${HOST_PLATFORM}-${HOST_ARCH}-${cni_version}.tgz\"\n  local -r cni_url=\"${STORAGE_ENDPOINT}/gke-release/cni-plugins/${cni_version}/${cni_tar}\"\n\n  if is-preloaded \"${cni_tar}\" \"${cni_hash}\"; then\n    echo \"${cni_tar} is preloaded.\"\n    return\n  fi\n\n  echo \"Downloading cni binaries\"\n  download-or-bust \"${cni_hash}\" \"${cni_url}\"\n  local -r cni_dir=\"${KUBE_HOME}/cni\"\n  mkdir -p \"${cni_dir}/bin\"\n  tar xzf \"${KUBE_HOME}/${cni_tar}\" -C \"${cni_dir}/bin\" --overwrite\n  mv \"${cni_dir}/bin\"/* \"${KUBE_BIN}\"\n  rmdir \"${cni_dir}/bin\"\n  rm -f \"${KUBE_HOME}/${cni_tar}\"\n\n  record-preload-info \"${cni_tar}\" \"${cni_hash}\"\n}\n\n# Install crictl binary.\n# Assumptions: HOST_PLATFORM and HOST_ARCH are specified by calling detect_host_info.\nfunction install-crictl {\n  if [[ -n \"${CRICTL_VERSION:-}\" ]]; then\n    local -r crictl_version=\"${CRICTL_VERSION}\"\n    local -r crictl_hash=\"${CRICTL_TAR_HASH}\"\n  else\n    local -r crictl_version=\"${DEFAULT_CRICTL_VERSION}\"\n    case \"${HOST_PLATFORM}/${HOST_ARCH}\" in\n      linux/amd64)\n        local -r crictl_hash=\"${DEFAULT_CRICTL_AMD64_SHA512}\"\n        ;;\n      linux/arm64)\n        local -r crictl_hash=\"${DEFAULT_CRICTL_ARM64_SHA512}\"\n        ;;\n      *)\n        echo \"Unrecognized version and platform/arch combination:\"\n        echo \"$DEFAULT_CRICTL_VERSION $HOST_PLATFORM/$HOST_ARCH\"\n        echo \"Set CRICTL_VERSION and CRICTL_TAR_HASH to overwrite\"\n        exit 1\n    esac\n  fi\n  local -r crictl=\"crictl-${crictl_version}-${HOST_PLATFORM}-${HOST_ARCH}.tar.gz\"\n\n  # Create crictl config file.\n  cat > /etc/crictl.yaml <<EOF\nruntime-endpoint: ${CONTAINER_RUNTIME_ENDPOINT:-unix:///run/containerd/containerd.sock}\nEOF\n\n  if is-preloaded \"${crictl}\" \"${crictl_hash}\"; then\n    echo \"crictl is preloaded\"\n    return\n  fi\n\n  echo \"Downloading crictl\"\n  local -r crictl_path=\"${STORAGE_ENDPOINT}/gke-release/cri-tools/${crictl_version}\"\n  download-or-bust \"${crictl_hash}\" \"${crictl_path}/${crictl}\"\n  tar xf \"${crictl}\"\n  mv crictl \"${KUBE_BIN}/crictl\"\n  rm -f \"${crictl}\"\n\n  record-preload-info \"${crictl}\" \"${crictl_hash}\"\n}\n\nfunction preload-pause-image {\n  local -r pause_image=\"${KUBE_DOCKER_REGISTRY}/${GKE_CONTAINERD_INFRA_CONTAINER}\"\n  if is-preloaded \"pause\" \"${pause_image}\"; then\n    echo \"pause image is preloaded\"\n    return\n  fi\n\n  # preloading pause image. It will be used in preloader and will be\n  # useful for staging builds where access_token is needed to pull the image\n  local access_token=\"\";\n\n  if access_token=$(get-credentials); then\n    \"${KUBE_BIN}/crictl\" pull --creds \"oauth2accesstoken:${access_token}\" \"${pause_image}\"\n  else\n    echo \"No access token. Pulling without it.\"\n    \"${KUBE_BIN}/crictl\" pull \"${pause_image}\"\n  fi\n\n  record-preload-info \"pause\" \"${pause_image}\"\n}\n\nfunction install-exec-auth-plugin {\n  if [[ ! \"${EXEC_AUTH_PLUGIN_URL:-}\" ]]; then\n      return\n  fi\n  local -r plugin_url=\"${EXEC_AUTH_PLUGIN_URL}\"\n  local -r plugin_hash=\"${EXEC_AUTH_PLUGIN_HASH}\"\n\n  if is-preloaded \"gke-exec-auth-plugin\" \"${plugin_hash}\"; then\n    echo \"gke-exec-auth-plugin is preloaded\"\n    return\n  fi\n\n  echo \"Downloading gke-exec-auth-plugin binary\"\n  download-or-bust \"${plugin_hash}\" \"${plugin_url}\"\n  mv \"${KUBE_HOME}/gke-exec-auth-plugin\" \"${KUBE_BIN}/gke-exec-auth-plugin\"\n  chmod a+x \"${KUBE_BIN}/gke-exec-auth-plugin\"\n\n  if [[ ! \"${EXEC_AUTH_PLUGIN_LICENSE_URL:-}\" ]]; then\n      return\n  fi\n  local -r license_url=\"${EXEC_AUTH_PLUGIN_LICENSE_URL}\"\n  echo \"Downloading gke-exec-auth-plugin license\"\n  download-or-bust \"\" \"${license_url}\"\n  mv \"${KUBE_HOME}/LICENSE\" \"${KUBE_BIN}/gke-exec-auth-plugin-license\"\n\n  record-preload-info \"gke-exec-auth-plugin\" \"${plugin_hash}\"\n}\n\nfunction install-kube-manifests {\n  # Put kube-system pods manifests in ${KUBE_HOME}/kube-manifests/.\n  local dst_dir=\"${KUBE_HOME}/kube-manifests\"\n  mkdir -p \"${dst_dir}\"\n  local manifests_tar_urls\n  while IFS= read -r url; do\n    manifests_tar_urls+=(\"$url\")\n  done < <(split-commas \"${KUBE_MANIFESTS_TAR_URL}\")\n  local -r manifests_tar=\"${manifests_tar_urls[0]##*/}\"\n  if [ -n \"${KUBE_MANIFESTS_TAR_HASH:-}\" ]; then\n    local -r manifests_tar_hash=\"${KUBE_MANIFESTS_TAR_HASH}\"\n  else\n    echo \"Downloading k8s manifests hash (not found in env)\"\n    download-or-bust \"\" \"${manifests_tar_urls[@]/.tar.gz/.tar.gz.sha512}\"\n    local -r manifests_tar_hash=$(cat \"${manifests_tar}.sha512\")\n  fi\n\n  if is-preloaded \"${manifests_tar}\" \"${manifests_tar_hash}\"; then\n    echo \"${manifests_tar} is preloaded.\"\n    return\n  fi\n\n  echo \"Downloading k8s manifests tar\"\n  download-or-bust \"${manifests_tar_hash}\" \"${manifests_tar_urls[@]}\"\n  tar xzf \"${KUBE_HOME}/${manifests_tar}\" -C \"${dst_dir}\" --overwrite\n  local -r kube_addon_registry=\"${KUBE_ADDON_REGISTRY:-k8s.gcr.io}\"\n  if [[ \"${kube_addon_registry}\" != \"k8s.gcr.io\" ]]; then\n    find \"${dst_dir}\" \\(-name '*.yaml' -or -name '*.yaml.in'\\) -print0 | \\\n      xargs -0 sed -ri \"s@(image:\\s.*)k8s.gcr.io@\\1${kube_addon_registry}@\"\n    find \"${dst_dir}\" \\(-name '*.manifest' -or -name '*.json'\\) -print0 | \\\n      xargs -0 sed -ri \"s@(image\\\":\\s+\\\")k8s.gcr.io@\\1${kube_addon_registry}@\"\n  fi\n  cp \"${dst_dir}/kubernetes/gci-trusty/gci-configure-helper.sh\" \"${KUBE_BIN}/configure-helper.sh\"\n  cp \"${dst_dir}/kubernetes/gci-trusty/configure-kubeapiserver.sh\" \"${KUBE_BIN}/configure-kubeapiserver.sh\"\n  if [[ -e \"${dst_dir}/kubernetes/gci-trusty/gke-internal-configure-helper.sh\" ]]; then\n    cp \"${dst_dir}/kubernetes/gci-trusty/gke-internal-configure-helper.sh\" \"${KUBE_BIN}/\"\n  fi\n  if [[ -e \"${dst_dir}/kubernetes/gci-trusty/node-registration-checker.sh\" ]]; then\n    cp \"${dst_dir}/kubernetes/gci-trusty/node-registration-checker.sh\" \"${KUBE_BIN}/\"\n  fi\n  cp \"${dst_dir}/kubernetes/gci-trusty/health-monitor.sh\" \"${KUBE_BIN}/health-monitor.sh\"\n  cp \"${dst_dir}/kubernetes/gci-trusty/networkd-monitor.sh\" \"${KUBE_BIN}/networkd-monitor.sh\"\n\n  rm -f \"${KUBE_HOME}/${manifests_tar}\"\n  rm -f \"${KUBE_HOME}/${manifests_tar}.sha512\"\n\n  record-preload-info \"${manifests_tar}\" \"${manifests_tar_hash}\"\n}\n\n# Installs hurl to ${KUBE_HOME}/bin/hurl if not already installed.\nfunction install-hurl {\n  cd \"${KUBE_HOME}\"\n  if [[ -f \"${KUBE_HOME}/bin/hurl\" ]]; then\n    echo \"install-hurl: hurl already installed\"\n    return\n  fi\n\n  local -r hurl_gcs_att=\"instance/attributes/hurl-gcs-url\"\n  local -r hurl_gcs_url=${HURL_GCS_URL:-$(get-metadata-value \"${hurl_gcs_att}\")}\n\n  if [[ -z \"${hurl_gcs_url}\" ]]; then\n    # URL not present in GCE Instance Metadata\n    echo \"install-hurl: Unable to find GCE metadata ${hurl_gcs_att}\"\n    return\n  fi\n\n  # Download hurl binary from a GCS bucket.\n  local -r hurl_bin=\"hurl\"\n  echo \"install-hurl: Installing hurl from ${hurl_gcs_url} ... \"\n  download-or-bust \"\" \"${hurl_gcs_url}\"\n  if [[ -f \"${KUBE_HOME}/${hurl_bin}\" ]]; then\n    chmod a+x ${KUBE_HOME}/${hurl_bin}\n    mv \"${KUBE_HOME}/${hurl_bin}\" \"${KUBE_BIN}/${hurl_bin}\"\n    echo \"install-hurl: hurl installed to ${KUBE_BIN}/${hurl_bin}\"\n    return\n  fi\n}\n\n# Installs inplace to ${KUBE_HOME}/bin/inplace if not already installed.\nfunction install-inplace {\n  cd \"${KUBE_HOME}\"\n  if [[ -f \"${KUBE_HOME}/bin/inplace\" ]]; then\n    echo \"install-inplace: inplace already installed\"\n    return\n  fi\n  local -r inplace_gcs_att=\"instance/attributes/inplace-gcs-url\"\n  local -r inplace_gcs_url=${INPLACE_GCS_URL:-$(get-metadata-value \"${inplace_gcs_att}\")}\n  if [[ -z \"${inplace_gcs_url}\" ]]; then\n    # URL not present in GCE Instance Metadata\n    echo \"install-inplace: Unable to find GCE metadata ${inplace_gcs_att}\"\n    return\n  fi\n  echo \"install-inplace: Installing inplace from ${inplace_gcs_url} ...\"\n  download-or-bust \"\" \"${inplace_gcs_url}\"\n  local -r inplace_bin=\"inplace\"\n  if [[ -f \"${KUBE_HOME}/${inplace_bin}\" ]]; then\n    mv \"${KUBE_HOME}/${inplace_bin}\" \"${KUBE_BIN}/${inplace_bin}\"\n    if [[ ! -d \"${KUBE_HOME}/${inplace_bin}\" ]]; then\n      mkdir -p \"${KUBE_HOME}/${inplace_bin}\"\n    fi\n    cat > \"${KUBE_HOME}/${inplace_bin}/inplace.hash\" <<EOF\n${inplace_gcs_url}\nEOF\n    echo \"install-inplace: inplace installed to ${KUBE_BIN}/${inplace_bin}\"\n    return\n  fi\n}\n\n# A function to download in-place component manifests if in-place agent is\n# present.\nfunction inplace-run-once {\n  if [[ -f \"${KUBE_HOME}/bin/inplace\" ]]; then\n    echo \"inplace-run-once: using inplace to download inplace component manefists\"\n    local dst_dir=\"${KUBE_HOME}/kube-manifests/kubernetes/gci-trusty\"\n    mkdir -p \"${dst_dir}/in-place\"\n    mkdir -p \"${dst_dir}/gce-extras/in-place\"\n    ${KUBE_HOME}/bin/inplace --mode=run-once --in_place_addon_path=\"${dst_dir}/gce-extras/in-place\" --master_pod_path=\"${dst_dir}/in-place\"\n  fi\n}\n\nfunction install-auger {\n  echo \"Downloading auger binary\"\n  if [[ -f \"${KUBE_HOME}/bin/auger\" ]]; then\n    echo \"auger is already installed\"\n    return\n  fi\n  AUGER_STORE_PATH=\"${AUGER_STORE_PATH:-${STORAGE_ENDPOINT}/gke-release-staging/auger}\"\n  AUGER_VERSION=\"${AUGER_VERSION:-v1.0.0-gke.1}\"\n  download-or-bust \"\" \"${AUGER_STORE_PATH}/${AUGER_VERSION}/auger.sha1\"\n  sha1=\"$(cat auger.sha1)\"\n  readonly sha1 # Declare readonly separately to avoid masking error values.\n  rm -f \"auger.sha1\"\n  download-or-bust \"${sha1}\" \"${AUGER_STORE_PATH}/${AUGER_VERSION}/auger\"\n  mv \"${KUBE_HOME}/auger\" \"${KUBE_HOME}/bin/auger\"\n  chmod a+x \"${KUBE_HOME}/bin/auger\"\n  record-preload-info \"auger\" \"${sha1}\"\n}\n\n# Extract etcdctl binary from etcd image.\nfunction install-etcdctl {\n  echo \"Installing etcdctl binary\"\n  if [[ -f \"${KUBE_HOME}/bin/etcdctl\" ]]; then\n    echo \"etcdctl is already installed\"\n    return\n  fi\n  local -r etcd_image=\"gcr.io/gke-master-images/etcd:${ETCDCTL_VERSION}\"\n  container_id=\"$(docker create \"${etcd_image}\" sh)\"\n  readonly containerId\n  docker cp \"${container_id}:usr/local/bin/etcdctl\" \"${KUBE_HOME}/bin/etcdctl\"\n  chmod a+x \"${KUBE_HOME}/bin/etcdctl\"\n  docker rm \"${container_id}\"\n  docker rmi \"${etcd_image}\"\n}\n\nfunction install-gcfsd {\n  echo \"Downloading Riptide FUSE client\"\n  if is-preloaded \"gcfsd\" \"${RIPTIDE_FUSE_VERSION}\"; then\n    echo \"gcfsd is preloaded.\"\n    return\n  fi\n\n  if [[ \"${HOST_ARCH}\" == \"arm64\" ]]; then\n    RIPTIDE_FUSE_STORE_PATH=\"${STORAGE_ENDPOINT}/gke-release/gcfsd/${RIPTIDE_FUSE_VERSION}/arm64\"\n    TAR_SHA=\"${RIPTIDE_FUSE_ARM64_SHA512}\"\n    BIN_SHA=\"${RIPTIDE_FUSE_BIN_ARM64_SHA512}\"\n  else\n    RIPTIDE_FUSE_STORE_PATH=\"${STORAGE_ENDPOINT}/gke-release/gcfsd/${RIPTIDE_FUSE_VERSION}\"\n    TAR_SHA=\"${RIPTIDE_FUSE_AMD64_SHA512}\"\n    BIN_SHA=\"${RIPTIDE_FUSE_BIN_AMD64_SHA512}\"\n  fi\n\n  echo \"Downloading tarball for gcfsd\"\n  download-or-bust \"${TAR_SHA}\" \"${RIPTIDE_FUSE_STORE_PATH}/gcfsd.tar.gz\"\n\n  download-or-bust \"${BIN_SHA}\" \"${RIPTIDE_FUSE_STORE_PATH}/gcfsd\"\n  mv \"${KUBE_HOME}/gcfsd\" \"${KUBE_HOME}/bin/gcfsd\"\n  chmod a+x \"${KUBE_HOME}/bin/gcfsd\"\n  record-preload-info \"gcfsd\" \"${RIPTIDE_FUSE_VERSION}\"\n}\n\nfunction install-riptide-snapshotter {\n  echo \"Downloading Riptide snapshotter\"\n  if is-preloaded \"containerd-gcfs-grpc\" \"${RIPTIDE_SNAPSHOTTER_VERSION}\"; then\n    echo \"containerd-gcfs-grpc is preloaded.\"\n    return\n  fi\n  RIPTIDE_SNAPSHOTTER_STORE_PATH=\"${STORAGE_ENDPOINT}/gke-release/gcfs-snapshotter/${RIPTIDE_SNAPSHOTTER_VERSION}\"\n\n  echo \"Downloading tarball for riptide-snapshotter\"\n  download-or-bust \"${RIPTIDE_SNAPSHOTTER_SHA512}\" \"${RIPTIDE_SNAPSHOTTER_STORE_PATH}/containerd-gcfs-grpc.tar.gz\"\n\n  if [[ \"${HOST_ARCH}\" == \"arm64\" ]]; then\n    RIPTIDE_SNAPSHOTTER_BINARY=\"containerd-gcfs-grpc-arm64\"\n    RIPTIDE_SNAPSHOTTER_BIN_SHA512=\"${RIPTIDE_SNAPSHOTTER_BIN_ARM64_SHA512}\"\n  else\n    RIPTIDE_SNAPSHOTTER_BINARY=\"containerd-gcfs-grpc\"\n    RIPTIDE_SNAPSHOTTER_BIN_SHA512=\"${RIPTIDE_SNAPSHOTTER_BIN_AMD64_SHA512}\"\n  fi\n\n  download-or-bust \"${RIPTIDE_SNAPSHOTTER_BIN_SHA512}\" \"${RIPTIDE_SNAPSHOTTER_STORE_PATH}/${RIPTIDE_SNAPSHOTTER_BINARY}\"\n  mv \"${KUBE_HOME}/${RIPTIDE_SNAPSHOTTER_BINARY}\" \"${KUBE_HOME}/bin/containerd-gcfs-grpc\"\n  chmod a+x \"${KUBE_HOME}/bin/containerd-gcfs-grpc\"\n  record-preload-info \"containerd-gcfs-grpc\" \"${RIPTIDE_SNAPSHOTTER_VERSION}\"\n}\n\n# Install Riptide FUSE client and Riptide snapshotter\nfunction install-riptide {\n  install-gcfsd\n  install-riptide-snapshotter\n}\n\nfunction install-auth-provider-gcp {\n  case \"${HOST_ARCH}\" in\n    amd64)\n      local -r auth_provider_gcp_hash=\"${AUTH_PROVIDER_GCP_HASH_LINUX_AMD64}\"\n      ;;\n    arm64)\n      local -r auth_provider_gcp_hash=\"${AUTH_PROVIDER_GCP_HASH_LINUX_ARM64}\"\n      ;;\n    *)\n      echo \"Unrecognized version and platform/arch combination: ${HOST_PLATFORM}/${HOST_ARCH}\"\n      exit 1\n  esac\n\n  if is-preloaded \"auth-provider-gcp\" \"${auth_provider_gcp_hash}\"; then\n    echo \"auth-provider-gcp is preloaded.\"\n    return\n  fi\n\n  local -r auth_provider_storage_url=\"${STORAGE_ENDPOINT}/gke-release/auth-provider-gcp/${AUTH_PROVIDER_GCP_VERSION}/${HOST_PLATFORM}_${HOST_ARCH}/auth-provider-gcp\"\n  echo \"Downloading auth-provider-gcp ${auth_provider_storage_url}\" .\n  download-or-bust \"${auth_provider_gcp_hash}\" \"${auth_provider_storage_url}\"\n\n  # Keep in sync with --image-credential-provider-bin-dir in cloud/kubernetes/distro/legacy/kube_env.go\n  mv \"${KUBE_HOME}/auth-provider-gcp\" \"${AUTH_PROVIDER_GCP_LINUX_BIN_DIR}\"\n  chmod a+x \"${AUTH_PROVIDER_GCP_LINUX_BIN_DIR}/auth-provider-gcp\"\n\n  record-preload-info \"auth-provider-gcp\" \"${auth_provider_gcp_hash}\"\n}\n\nfunction download-gvisor-installer {\n  local -r installer_image_hash=$1\n  local -r installer_image=\"${KUBE_DOCKER_REGISTRY}/gke-gvisor-installer@sha256:${installer_image_hash}\"\n  if access_token=$(get-credentials); then\n    \"${KUBE_BIN}/crictl\" pull --creds \"oauth2accesstoken:${access_token}\" \"${installer_image}\"\n  else\n    \"${KUBE_BIN}/crictl\" pull \"${installer_image}\"\n  fi\n}\n\nfunction configure-cgroup-mode {\n  if which cgroup_helper > /dev/null 2>\u00261; then\n    if [[ \"${CGROUP_MODE:-}\" == \"v1\" ]] \u0026\u0026 cgroup_helper show | grep -q 'unified'; then\n      cgroup_helper set hybrid\n      echo \"set cgroup config to hybrid, now rebooting...\"\n      reboot\n    elif [[ \"${CGROUP_MODE:-}\" == \"v2\" ]] \u0026\u0026 cgroup_helper show | grep -q 'hybrid'; then\n      cgroup_helper set unified\n      echo \"set cgroup config to unified, now rebooting...\"\n      reboot\n    fi\n  fi\n}\n\n# A helper function for loading a docker image. It keeps trying up to 5 times.\n#\n# $1: Full path of the docker image\nfunction try-load-docker-image {\n  local -r img=$1\n  echo \"Try to load docker image file ${img}\"\n  # Temporarily turn off errexit, because we don't want to exit on first failure.\n  set +e\n  local -r max_attempts=5\n  local -i attempt_num=1\n\n  if [[ \"${CONTAINER_RUNTIME_NAME:-}\" == \"containerd\" || \"${CONTAINERD_TEST:-}\"  == \"containerd\" ]]; then\n    load_image_command=${LOAD_IMAGE_COMMAND:-ctr -n=k8s.io images import}\n  else\n    load_image_command=\"${LOAD_IMAGE_COMMAND:-}\"\n  fi\n\n  # Deliberately word split load_image_command\n  # shellcheck disable=SC2086\n  until timeout 30 ${load_image_command} \"${img}\"; do\n    if [[ \"${attempt_num}\" == \"${max_attempts}\" ]]; then\n      echo \"Fail to load docker image file ${img} using ${load_image_command} after ${max_attempts} retries. Exit!!\"\n      exit 1\n    else\n      attempt_num=$((attempt_num+1))\n      sleep 5\n    fi\n  done\n  # Re-enable errexit.\n  set -e\n}\n\n# Loads kube-system docker images. It is better to do it before starting kubelet,\n# as kubelet will restart docker daemon, which may interfere with loading images.\nfunction load-docker-images {\n  echo \"Start loading kube-system docker images\"\n  local -r img_dir=\"${KUBE_HOME}/kube-docker-files\"\n  if [[ \"${KUBERNETES_MASTER:-}\" == \"true\" ]]; then\n    try-load-docker-image \"${img_dir}/kube-apiserver.tar\"\n    try-load-docker-image \"${img_dir}/kube-controller-manager.tar\"\n    try-load-docker-image \"${img_dir}/kube-scheduler.tar\"\n  else\n    try-load-docker-image \"${img_dir}/kube-proxy.tar\"\n  fi\n}\n\n# If we are on ubuntu we can try to install containerd\nfunction install-containerd-ubuntu {\n  # bailout if we are not on ubuntu\n  if ! is-ubuntu; then\n    echo \"Unable to automatically install containerd in non-ubuntu image. Bailing out...\"\n    exit 2\n  fi\n\n  # Install dependencies, some of these are already installed in the image but\n  # that's fine since they won't re-install and we can reuse the code below\n  # for another image someday.\n  apt-get update\n  apt-get install -y --no-install-recommends \\\n    apt-transport-https \\\n    ca-certificates \\\n    socat \\\n    curl \\\n    gnupg2 \\\n    software-properties-common \\\n    lsb-release\n\n  release=$(lsb_release -cs)\n\n  # Add the Docker apt-repository (as we install containerd from there)\n  # shellcheck disable=SC2086\n  curl ${CURL_FLAGS} \\\n    --location \\\n    \"https://download.docker.com/${HOST_PLATFORM}/$(. /etc/os-release; echo \"$ID\")/gpg\" \\\n  | apt-key add -\n  add-apt-repository \\\n    \"deb [arch=${HOST_ARCH}] https://download.docker.com/${HOST_PLATFORM}/$(. /etc/os-release; echo \"$ID\") \\\n    $release stable\"\n\n  # Install containerd from Docker repo\n  apt-get update \u0026\u0026 \\\n    apt-get install -y --no-install-recommends containerd\n  rm -rf /var/lib/apt/lists/*\n\n  # Override to latest versions of containerd and runc\n  systemctl stop containerd\n  if [[ -n \"${UBUNTU_INSTALL_CONTAINERD_VERSION:-}\" ]]; then\n    # TODO(https://github.com/containerd/containerd/issues/2901): Remove this check once containerd has arm64 release.\n    if [[ $(dpkg --print-architecture) != \"amd64\" ]]; then\n      echo \"Unable to automatically install containerd in non-amd64 image. Bailing out...\"\n      exit 2\n    fi\n    # containerd versions have slightly different url(s), so try both\n    # shellcheck disable=SC2086\n    ( curl ${CURL_FLAGS} \\\n        --location \\\n        \"https://github.com/containerd/containerd/releases/download/${UBUNTU_INSTALL_CONTAINERD_VERSION}/containerd-${UBUNTU_INSTALL_CONTAINERD_VERSION:1}-${HOST_PLATFORM}-${HOST_ARCH}.tar.gz\" \\\n      || curl ${CURL_FLAGS} \\\n        --location \\\n        \"https://github.com/containerd/containerd/releases/download/${UBUNTU_INSTALL_CONTAINERD_VERSION}/containerd-${UBUNTU_INSTALL_CONTAINERD_VERSION:1}.${HOST_PLATFORM}-${HOST_ARCH}.tar.gz\" ) \\\n    | tar --overwrite -xzv -C /usr/\n  fi\n  if [[ -n \"${UBUNTU_INSTALL_RUNC_VERSION:-}\" ]]; then\n    # TODO: Remove this check once runc has arm64 release.\n    if [[ $(dpkg --print-architecture) != \"amd64\" ]]; then\n      echo \"Unable to automatically install runc in non-amd64. Bailing out...\"\n      exit 2\n    fi\n    # shellcheck disable=SC2086\n    curl ${CURL_FLAGS} \\\n      --location \\\n      \"https://github.com/opencontainers/runc/releases/download/${UBUNTU_INSTALL_RUNC_VERSION}/runc.${HOST_ARCH}\" --output /usr/sbin/runc \\\n    \u0026\u0026 chmod 755 /usr/sbin/runc\n  fi\n  sudo systemctl start containerd\n}\n\n# A helper function for retagging a docker image.\n# $1: Image prefix\n# $2: Image tag\n# $3: Destination tag\nfunction retag-docker-image {\n  local -r img_prefix=$1\n  local -r img_tag=$2\n  local -r dest_tag=$3\n  if [[ \"${img_tag}\" == \"${dest_tag}\" ]]; then\n    echo \"Source image tag: ${img_tag} and destination image tag: ${dest_tag} are the same. Skipping retagging.\"\n  else\n    echo \"Retagging all images with prefix: ${img_prefix} and tag: ${img_tag} with new tag: ${dest_tag}\"\n    local src_img=\"\"\n    for src_img in $(ctr -n=k8s.io images list -q | grep \"/${img_prefix}\" | grep \":${img_tag}$\"); do\n      dest_img=${src_img/:${img_tag}/:${dest_tag}}\n      cmd=\"ctr -n=k8s.io image tag ${src_img} ${dest_img} --force\"\n      echo \"Retag command: ${cmd}\"\n      ${cmd}\n    done\n  fi\n}\n\n\n# Retags kube-system docker images with passed in kube-apiserver/kubelet versions.\nfunction retag-docker-images {\n  echo \"Start retagging kube-system docker images\"\n  local src_tag=\"\"\n  local dest_tag=\"\"\n  if [[ \"${KUBERNETES_MASTER:-}\" == \"true\" ]]; then\n    if [[ -n \"${KUBE_APISERVER_VERSION:-}\" ]]; then\n      src_tag=$(cat /home/kubernetes/kube-docker-files/kube-apiserver.docker_tag)\n      # Docker tags cannot contain '+', make CI versions a valid docker tag.\n      dest_tag=${KUBE_APISERVER_VERSION/+/_}\n      retag-docker-image \"kube-apiserver\" \"${src_tag}\" \"${dest_tag}\"\n      retag-docker-image \"kube-controller-manager\" \"${src_tag}\" \"${dest_tag}\"\n      retag-docker-image \"kube-scheduler\" \"${src_tag}\" \"${dest_tag}\"\n    fi\n  else\n    if [[ -n \"${KUBELET_VERSION:-}\" ]]; then\n      src_tag=$(cat /home/kubernetes/kube-docker-files/kube-proxy.docker_tag)\n      # Docker tags cannot contain '+', make CI versions a valid docker tag.\n      dest_tag=${KUBELET_VERSION/+/_}\n      retag-docker-image \"kube-proxy\" \"${src_tag}\" \"${dest_tag}\"\n    fi\n  fi\n}\n\n\nfunction ensure-container-runtime {\n  if [[ \"${CONTAINER_RUNTIME}\" == \"docker\" ]]; then\n    echo \"Dockershim is not supported. Container runtime must be set to containerd\"\n    exit 2\n  fi\n\n  # Install containerd/runc if requested\n  if [[ -n \"${UBUNTU_INSTALL_CONTAINERD_VERSION:-}\" || -n \"${UBUNTU_INSTALL_RUNC_VERSION:-}\" ]]; then\n    install-containerd-ubuntu\n  fi\n  # Verify presence and print versions of ctr, containerd, runc\n  if ! command -v ctr >/dev/null 2>\u00261; then\n    echo \"ERROR ctr not found. Aborting.\"\n    exit 2\n  fi\n  ctr --version\n\n  if ! command -v containerd >/dev/null 2>\u00261; then\n    echo \"ERROR containerd not found. Aborting.\"\n    exit 2\n  fi\n  containerd --version\n\n  if ! command -v runc >/dev/null 2>\u00261; then\n    echo \"ERROR runc not found. Aborting.\"\n    exit 2\n  fi\n  runc --version\n}\n\n# Downloads kubernetes binaries and kube-system manifest tarball, unpacks them,\n# and places them into suitable directories. Files are placed in /home/kubernetes.\nfunction install-kube-binary-config {\n  cd \"${KUBE_HOME}\"\n  local server_binary_tar_urls\n  while IFS= read -r url; do\n    server_binary_tar_urls+=(\"$url\")\n  done < <(split-commas \"${SERVER_BINARY_TAR_URL}\")\n  local -r server_binary_tar=\"${server_binary_tar_urls[0]##*/}\"\n  if [[ -n \"${SERVER_BINARY_TAR_HASH:-}\" ]]; then\n    local -r server_binary_tar_hash=\"${SERVER_BINARY_TAR_HASH}\"\n  else\n    echo \"Downloading binary release sha512 (not found in env)\"\n    download-or-bust \"\" \"${server_binary_tar_urls[@]/.tar.gz/.tar.gz.sha512}\"\n    local -r server_binary_tar_hash=$(cat \"${server_binary_tar}.sha512\")\n  fi\n\n  if is-preloaded \"${server_binary_tar}\" \"${server_binary_tar_hash}\"; then\n    echo \"${server_binary_tar} is preloaded.\"\n  else\n    echo \"Downloading binary release tar\"\n    download-or-bust \"${server_binary_tar_hash}\" \"${server_binary_tar_urls[@]}\"\n    tar xzf \"${KUBE_HOME}/${server_binary_tar}\" -C \"${KUBE_HOME}\" --overwrite\n    # Copy docker_tag and image files to ${KUBE_HOME}/kube-docker-files.\n    local -r src_dir=\"${KUBE_HOME}/kubernetes/server/bin\"\n    local dst_dir=\"${KUBE_HOME}/kube-docker-files\"\n    mkdir -p \"${dst_dir}\"\n    cp \"${src_dir}/\"*.docker_tag \"${dst_dir}\"\n    if [[ \"${KUBERNETES_MASTER:-}\" == \"false\" ]]; then\n      cp \"${src_dir}/kube-proxy.tar\" \"${dst_dir}\"\n    else\n      cp \"${src_dir}/kube-apiserver.tar\" \"${dst_dir}\"\n      cp \"${src_dir}/kube-controller-manager.tar\" \"${dst_dir}\"\n      cp \"${src_dir}/kube-scheduler.tar\" \"${dst_dir}\"\n      cp -r \"${KUBE_HOME}/kubernetes/addons\" \"${dst_dir}\"\n    fi\n    load-docker-images\n    mv \"${src_dir}/kubelet\" \"${KUBE_BIN}\"\n    mv \"${src_dir}/kubectl\" \"${KUBE_BIN}\"\n\n    # Some older images have LICENSES baked-in as a file. Presumably they will\n    # have the directory baked-in eventually.\n    rm -rf \"${KUBE_HOME}\"/LICENSES\n    mv \"${KUBE_HOME}/kubernetes/LICENSES\" \"${KUBE_HOME}\"\n    mv \"${KUBE_HOME}/kubernetes/kubernetes-src.tar.gz\" \"${KUBE_HOME}\"\n\n    record-preload-info \"${server_binary_tar}\" \"${server_binary_tar_hash}\"\n  fi\n\n  retag-docker-images\n\n  if [[ \"${NETWORK_PROVIDER:-}\" == \"kubenet\" ]] || \\\n     [[ \"${NETWORK_PROVIDER:-}\" == \"cni\" ]]; then\n    install-cni-binaries\n  fi\n\n  # Put kube-system pods manifests in ${KUBE_HOME}/kube-manifests/.\n  install-kube-manifests\n  chmod -R 755 \"${KUBE_BIN}\"\n\n  # Install gci mounter related artifacts to allow mounting storage volumes in GCI\n  install-gci-mounter-tools\n\n  # Remount the Flexvolume directory with the \"exec\" option, if needed.\n  if [[ \"${REMOUNT_VOLUME_PLUGIN_DIR:-}\" == \"true\" \u0026\u0026 -n \"${VOLUME_PLUGIN_DIR:-}\" ]]; then\n    remount-flexvolume-directory \"${VOLUME_PLUGIN_DIR}\"\n  fi\n\n  # Install crictl on each node.\n  install-crictl\n\n  # Preload pause image\n  preload-pause-image\n\n  # Copy health check binaries to a tmpfs mount to reduce block IO usage.\n  setup-shm-healthcheck-binaries\n\n  # TODO(awly): include the binary and license in the OS image.\n  install-exec-auth-plugin\n\n  if [[ \"${KUBERNETES_MASTER:-}\" == \"false\" ]] \u0026\u0026 \\\n     [[ \"${ENABLE_NODE_PROBLEM_DETECTOR:-}\" == \"standalone\" ]]; then\n    install-node-problem-detector\n    install-npd-custom-plugins\n  fi\n\n  # Clean up.\n  rm -rf \"${KUBE_HOME}/kubernetes\"\n  rm -f \"${KUBE_HOME}/${server_binary_tar}\"\n  rm -f \"${KUBE_HOME}/${server_binary_tar}.sha512\"\n}\n\nfunction setup-shm-healthcheck-binaries() {\n  if [[ \"${KUBERNETES_MASTER:-}\" == \"true\" ]]; then\n    return\n  fi\n  if [[ \"${ENABLE_SHM_HEALTHCHECK_BINARIES:-}\" != \"true\" ]];then\n    return\n  fi\n\n  local -r shm_dir=\"${HEALTHCHECK_SHM_DIR:-/dev/kube_shm}\"\n  local -r shm_bin_dir=\"${shm_dir}/bin\"\n\n  mkdir -p \"$shm_dir\"\n  mount -t tmpfs -o exec none \"$shm_dir\"\n  mkdir \"${shm_bin_dir}\"\n\n  cp -f \"${KUBE_BIN}/crictl\" \"${shm_bin_dir}/crictl\"\n  cp -f \"$(which curl)\" \"${shm_bin_dir}/curl\"\n}\n\nfunction install-extra-node-requirements() {\n  if [[ \"${KUBERNETES_MASTER:-}\" != \"false\" ]]; then\n    return\n  fi\n}\n\nfunction configure-pga-if-needed() {\n  echo \"Detecting connectivity to ${STORAGE_ENDPOINT}...\"\n  local status=0\n  curl --ipv4 -L --connect-timeout 10 --retry 3  --retry-connrefused ${STORAGE_ENDPOINT} || status=\"$?\"\n  # connection is refused(7) or timeout(28).\n  if [[ \"${status}\" == \"7\" || \"${status}\" == \"28\" ]]; then\n    status=0\n    local pga_ip\n    pga_ip=`curl ${PGA_ENDPOINT} -w '%{remote_ip}' --connect-timeout 10 -s -o /dev/null` || status=\"$?\"\n    if [[ \"${status}\" == \"0\" ]]; then\n      echo \"Configure /etc/hosts to use private google access\"\n      echo \"$pga_ip ${STORAGE_ENDPOINT#https://}\" >> /etc/hosts\n      echo \"$pga_ip ${KUBE_DOCKER_REGISTRY}\" >> /etc/hosts\n    fi\n  fi\n}\n\n# This function detects the platform/arch of the machine where the script runs,\n# and sets the HOST_PLATFORM and HOST_ARCH environment variables accordingly.\n# Callers can specify HOST_PLATFORM_OVERRIDE and HOST_ARCH_OVERRIDE to skip the detection.\n# This function is adapted from the detect_client_info function in cluster/get-kube-binaries.sh\n# and kube::util::host_os, kube::util::host_arch functions in hack/lib/util.sh\n# This function should be synced with detect_host_info in ./configure-helper.sh\nfunction detect_host_info() {\n  HOST_PLATFORM=${HOST_PLATFORM_OVERRIDE:-\"$(uname -s)\"}\n  case \"${HOST_PLATFORM}\" in\n    Linux|linux)\n      HOST_PLATFORM=\"linux\"\n      ;;\n    *)\n      echo \"Unknown, unsupported platform: ${HOST_PLATFORM}.\" >\u00262\n      echo \"Supported platform(s): linux.\" >\u00262\n      echo \"Bailing out.\" >\u00262\n      exit 2\n  esac\n\n  HOST_ARCH=${HOST_ARCH_OVERRIDE:-\"$(uname -m)\"}\n  case \"${HOST_ARCH}\" in\n    x86_64*|i?86_64*|amd64*)\n      HOST_ARCH=\"amd64\"\n      ;;\n    aHOST_arch64*|aarch64*|arm64*)\n      HOST_ARCH=\"arm64\"\n      ;;\n    *)\n      echo \"Unknown, unsupported architecture (${HOST_ARCH}).\" >\u00262\n      echo \"Supported architecture(s): amd64 and arm64.\" >\u00262\n      echo \"Bailing out.\" >\u00262\n      exit 2\n      ;;\n  esac\n}\n\n# Retries a command forever with a delay between retries.\n# Args:\n#  $1    : delay between retries, in seconds.\n#  $2... : the command to run.\nfunction retry-forever {\n  local -r delay=\"$1\"\n  shift 1\n\n  until \"$@\"; do\n    echo \"== $* failed, retrying after ${delay}s\"\n    sleep \"${delay}\"\n  done\n}\n\n# Initializes variables used by the log-* functions.\n#\n# get-metadata-value must be defined before calling this function.\n#\n# NOTE: this function is duplicated in configure-helper.sh, any changes here\n# should be duplicated there as well.\nfunction log-init {\n  # Used by log-* functions.\n  LOG_CLUSTER_ID=${LOG_CLUSTER_ID:-$(get-metadata-value 'instance/attributes/cluster-uid' 'get-metadata-value-error')}\n  LOG_INSTANCE_NAME=$(hostname || echo 'hostname-error')\n  LOG_BOOT_ID=$(journalctl --list-boots | grep -E '^ *0' | awk '{print $2}' || echo 'journalctl-error')\n  declare -Ag LOG_START_TIMES\n  declare -ag LOG_TRAP_STACK\n\n  LOG_STATUS_STARTED='STARTED'\n  LOG_STATUS_COMPLETED='COMPLETED'\n  LOG_STATUS_ERROR='ERROR'\n}\n\n# Sets an EXIT trap.\n# Args:\n#   $1:... : the trap command.\n#\n# NOTE: this function is duplicated in configure-helper.sh, any changes here\n# should be duplicated there as well.\nfunction log-trap-push {\n  local t=\"${*:1}\"\n  LOG_TRAP_STACK+=(\"${t}\")\n  # shellcheck disable=2064\n  trap \"${t}\" EXIT\n}\n\n# Removes and restores an EXIT trap.\n#\n# NOTE: this function is duplicated in configure-helper.sh, any changes here\n# should be duplicated there as well.\nfunction log-trap-pop {\n  # Remove current trap.\n  unset 'LOG_TRAP_STACK[-1]'\n\n  # Restore previous trap.\n  if [ ${#LOG_TRAP_STACK[@]} -ne 0 ]; then\n    local t=\"${LOG_TRAP_STACK[-1]}\"\n    # shellcheck disable=2064\n    trap \"${t}\" EXIT\n  else\n    # If no traps in stack, clear.\n    trap EXIT\n  fi\n}\n\n# Logs the end of a bootstrap step that errored.\n# Args:\n#  $1 : bootstrap step name.\n#\n# NOTE: this function is duplicated in configure-helper.sh, any changes here\n# should be duplicated there as well.\nfunction log-error {\n  local bootstep=\"$1\"\n\n  log-proto \"${bootstep}\" \"${LOG_STATUS_ERROR}\" \"encountered non-zero exit code\"\n}\n\n# Wraps a command with bootstrap logging.\n# Args:\n#   $1    : bootstrap step name.\n#   $2... : the command to run.\n#\n# NOTE: this function is duplicated in configure-helper.sh, any changes here\n# should be duplicated there as well.\nfunction log-wrap {\n  local bootstep=\"$1\"\n  local command=\"${*:2}\"\n\n  log-trap-push \"log-error ${bootstep}\"\n  log-proto \"${bootstep}\" \"${LOG_STATUS_STARTED}\"\n  $command\n  log-proto \"${bootstep}\" \"${LOG_STATUS_COMPLETED}\"\n  log-trap-pop\n}\n\n# Logs a bootstrap step start. Prefer log-wrap.\n# Args:\n#   $1 : bootstrap step name.\n#\n# NOTE: this function is duplicated in configure-helper.sh, any changes here\n# should be duplicated there as well.\nfunction log-start {\n  local bootstep=\"$1\"\n\n  log-trap-push \"log-error ${bootstep}\"\n  log-proto \"${bootstep}\" \"${LOG_STATUS_STARTED}\"\n}\n\n# Logs a bootstrap step end. Prefer log-wrap.\n# Args:\n#   $1 : bootstrap step name.\n#\n# NOTE: this function is duplicated in configure-helper.sh, any changes here\n# should be duplicated there as well.\nfunction log-end {\n  local bootstep=\"$1\"\n\n  log-proto \"${bootstep}\" \"${LOG_STATUS_COMPLETED}\"\n  log-trap-pop\n}\n\n# Writes a log proto to stdout.\n# Args:\n#   $1: bootstrap step name.\n#   $2: status. Either 'STARTED', 'COMPLETED', or 'ERROR'.\n#   $3: optional status reason.\n#\n# NOTE: this function is duplicated in configure-helper.sh, any changes here\n# should be duplicated there as well.\nfunction log-proto {\n  local bootstep=\"$1\"\n  local status=\"$2\"\n  local status_reason=\"${3:-}\"\n\n  # Get current time.\n  local current_time\n  current_time=\"$(date --utc '+%s.%N')\"\n  # ...formatted as UTC RFC 3339.\n  local timestamp\n  timestamp=\"$(date --utc --date=\"@${current_time}\" '+%FT%T.%NZ')\"\n\n  # Calculate latency.\n  local latency='null'\n  if [ \"${status}\" == \"${LOG_STATUS_STARTED}\" ]; then\n    LOG_START_TIMES[\"${bootstep}\"]=\"${current_time}\"\n  else\n    local start_time=\"${LOG_START_TIMES[\"${bootstep}\"]}\"\n    unset 'LOG_START_TIMES['\"${bootstep}\"']'\n\n    # Bash cannot do non-integer math, shell out to awk.\n    latency=\"$(echo \"${current_time} ${start_time}\" | awk '{print $1 - $2}')s\"\n\n    # The default latency is null which cannot be wrapped as a string so we must\n    # do it here instead of the printf.\n    latency=\"\\\"${latency}\\\"\"\n  fi\n\n  printf '[cloud.kubernetes.monitoring.proto.SerialportLog] {\"cluster_hash\":\"%s\",\"vm_instance_name\":\"%s\",\"boot_id\":\"%s\",\"timestamp\":\"%s\",\"bootstrap_status\":{\"step_name\":\"%s\",\"status\":\"%s\",\"status_reason\":\"%s\",\"latency\":%s}}\\n' \\\n  \"${LOG_CLUSTER_ID}\" \"${LOG_INSTANCE_NAME}\" \"${LOG_BOOT_ID}\" \"${timestamp}\" \"${bootstep}\" \"${status}\" \"${status_reason}\" \"${latency}\"\n}\n\n# Prelaod components for both - preloader and runtime\n# Variables needed for this function to work will be set by the preloader\nfunction preload {\n  cd \"${KUBE_HOME}\"\n  if [[ \"${ENABLE_AUTH_PROVIDER_GCP:-\"\"}\" == \"true\" ]]; then\n    log-wrap 'InstallExternalCredentialProvider' install-auth-provider-gcp\n  fi\n\n  if [[ \"${KUBERNETES_MASTER:-}\" != \"true\" \u0026\u0026 -n \"${GVISOR_INSTALLER_IMAGE_HASH:-}\" ]]; then\n    log-wrap 'DownloadGvisorInstaller' download-gvisor-installer \"${GVISOR_INSTALLER_IMAGE_HASH}\"\n  fi\n}\n\n######### Main Function ##########\nlog-init\ndetect_host_info\n\n# Preloader will source this script, and skip the main function. The preloader\n# will choose what to preload by calling install-X functions directly.\n# When configure.sh is sourced by the preload script, $0 and $BASH_SOURCE are\n# different. $BASH_SOURCE still contains the path of configure.sh, while $0 is\n# the path of the preload script.\nif [[ \"$0\" != \"$BASH_SOURCE\" \u0026\u0026 \"${IS_PRELOADER:-\"false\"}\" == \"true\" ]]; then\n  # preload common components\n  preload\n  echo \"Running in preloader instead of VM bootsrapping. Skipping installation steps as preloader script will source configure.sh and call all non-common functions.\"\n  return\nfi\n\nlog-start 'ConfigureMain'\necho \"Start to install kubernetes files\"\n\n# if install fails, message-of-the-day (motd) will warn at login shell\nlog-wrap 'SetBrokenMotd' set-broken-motd\n\nKUBE_HOME=\"/home/kubernetes\"\nKUBE_BIN=\"${KUBE_HOME}/bin\"\n\nif [[ \"$(is-master)\" == \"true\" ]]; then\n  log-wrap 'InstallHurl' install-hurl\n  log-wrap 'InstallInplace' install-inplace\nfi\n\n# download and source kube-env\nlog-wrap 'DownloadKubeEnv' download-kube-env\nlog-wrap 'SourceKubeEnv' source \"${KUBE_HOME}/kube-env\"\n\nif [[ \"${CONFIGURE_PGA}\" == \"true\" ]]; then\n  configure-pga-if-needed\nfi\n\nlog-wrap 'ConfigureCgroupMode' configure-cgroup-mode\n\nlog-wrap 'DownloadKubeletConfig' download-kubelet-config \"${KUBE_HOME}/kubelet-config.yaml\"\n\nif [[ \"${KUBERNETES_MASTER:-}\" == \"true\" ]]; then\n  log-wrap 'DownloadKubeMasterCerts' download-kube-master-certs-hurl\nfi\n\nif docker-installed; then\n  # We still need to configure docker so it wouldn't reserver the 172.17.0/16 subnet\n  # And if somebody will start docker to build or pull something, logging will also be set up\n  log-wrap 'AssembleDockerFlags' assemble-docker-flags\nfi\n\n# preload common components\npreload\n\n# ensure chosen container runtime is present\nlog-wrap 'EnsureContainerRuntime' ensure-container-runtime\n\n# binaries and kube-system manifests\nlog-wrap 'InstallKubeBinaryConfig' install-kube-binary-config\n\n# install Riptide components on non-Ubuntu nodes\nif ! is-ubuntu \u0026\u0026 [[ \"${KUBERNETES_MASTER:-}\" != \"true\" ]]; then\n  log-wrap 'InstallRiptide' install-riptide\nfi\n\n# download inplace component manifests\nif [[ \"${KUBERNETES_MASTER:-}\" == \"true\" ]]; then\n  log-wrap 'InplaceRunOnce' retry-forever 30 inplace-run-once\nfi\n\necho \"Done for installing kubernetes files\"\nlog-end 'ConfigureMain'\n"
    disable-legacy-endpoints   = "true"
    gci-metrics-enabled        = "true"
    gci-update-strategy        = "update_disabled"
    google-compute-enable-pcid = "true"
    kube-env                   = "ALLOCATE_NODE_CIDRS: \"true\"\nAPI_SERVER_TEST_LOG_LEVEL: --v=3\nAUTOSCALER_ENV_VARS: kube_reserved=cpu=70m,memory=2623Mi,ephemeral-storage=41Gi;node_labels=cloud.google.com/gke-boot-disk=pd-balanced,cloud.google.com/gke-container-runtime=containerd,cloud.google.com/gke-cpu-scaling-level=2,cloud.google.com/gke-logging-variant=DEFAULT,cloud.google.com/gke-max-pods-per-node=110,cloud.google.com/gke-nodepool=default-pool,cloud.google.com/gke-os-distribution=cos,cloud.google.com/gke-provisioning=standard,cloud.google.com/gke-stack-type=IPV4,cloud.google.com/machine-family=e2;arch=amd64;os=linux;os_distribution=cos;evictionHard=memory.available=100Mi,nodefs.available=10%,nodefs.inodesFree=5%,pid.available=10%\nCA_CERT: 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\nCLOUD_MONARCH_ENDPOINT: https://monitoring.googleapis.com/\nCLUSTER_IP_RANGE: 10.84.0.0/14\nCLUSTER_NAME: private-cluster-3\nCONFIGURE_PGA: \"true\"\nCONTAINER_RUNTIME: containerd\nCONTAINER_RUNTIME_ENDPOINT: unix:///run/containerd/containerd.sock\nCONTAINER_RUNTIME_NAME: containerd\nCONTAINERD_MAX_CONTAINER_LOG_LINE: \"262144\"\nCREATE_BOOTSTRAP_KUBECONFIG: \"false\"\nDETECT_LOCAL_MODE: NodeCIDR\nDETECT_MTU: \"true\"\nDNS_DOMAIN: cluster.local\nDNS_SERVER_IP: 10.81.96.10\nDOCKER_REGISTRY_MIRROR_URL: https://mirror.gcr.io\nELASTICSEARCH_LOGGING_REPLICAS: \"1\"\nENABLE_CLUSTER_DNS: \"true\"\nENABLE_CLUSTER_LOGGING: \"false\"\nENABLE_CLUSTER_MONITORING: none\nENABLE_CLUSTER_REGISTRY: \"false\"\nENABLE_CLUSTER_UI: \"true\"\nENABLE_CONNTRACK_EXEMPT_HC: \"true\"\nENABLE_CONTAINERD_METRICS: \"true\"\nENABLE_L7_LOADBALANCING: glbc\nENABLE_LATEST_NPD: \"true\"\nENABLE_METADATA_AGENT: \"\"\nENABLE_METRICS_SERVER: \"true\"\nENABLE_NODE_BFQ_IO_SCHEDULER: \"true\"\nENABLE_NODE_LOGGING: \"false\"\nENABLE_NODE_PROBLEM_DETECTOR: standalone\nENABLE_NODE_REGISTRATION_CHECKER: \"true\"\nENABLE_NODELOCAL_DNS: \"false\"\nENABLE_SHM_HEALTHCHECK_BINARIES: \"true\"\nENABLE_SYSCTL_TUNING: \"true\"\nENV_TIMESTAMP: \"2023-11-24T23:55:10+00:00\"\nEXEC_AUTH_PLUGIN_HASH: 1e3e03770805fd4f670f51f4f138f2f9af0ffe16c531d6512bcaec02aab98cec7977da5a84ffbc6509e02989db613c1535f0e14af871078b9520a9f2325374b4\nEXEC_AUTH_PLUGIN_LICENSE_URL: https://storage.googleapis.com/gke-prod-binaries/gke-exec-auth-plugin/8e4840462445ac0edd615a1e6175f44efda4908a/LICENSE\nEXEC_AUTH_PLUGIN_SHA1: 96035ca5744c1d4bd797974ac8f3e1ccbf105ea7\nEXEC_AUTH_PLUGIN_URL: https://storage.googleapis.com/gke-prod-binaries/gke-exec-auth-plugin/8e4840462445ac0edd615a1e6175f44efda4908a/linux_amd64/gke-exec-auth-plugin\nEXTRA_DOCKER_OPTS: --insecure-registry 10.0.0.0/8\nEXTRA_POD_SYSCTLS: net.ipv6.conf.all.disable_ipv6=1,net.ipv6.conf.default.disable_ipv6=1\nFEATURE_GATES: InTreePluginAWSUnregister=true,InTreePluginAzureDiskUnregister=true,InTreePluginvSphereUnregister=true,RotateKubeletServerCertificate=true,ExecProbeTimeout=false,CSIMigrationGCE=true\nFLUENTD_CONTAINER_RUNTIME_SERVICE: containerd\nGVISOR_METRIC_SERVER: 127.0.0.1:9115\nHEAPSTER_USE_NEW_STACKDRIVER_RESOURCES: \"true\"\nHEAPSTER_USE_OLD_STACKDRIVER_RESOURCES: \"false\"\nHPA_USE_REST_CLIENTS: \"true\"\nINSTANCE_PREFIX: gke-private-cluster-3-cfa1fee5\nKUBE_ADDON_REGISTRY: k8s.gcr.io\nKUBE_CLUSTER_DNS: 10.81.96.10\nKUBE_DOCKER_REGISTRY: gke.gcr.io\nKUBE_MANIFESTS_TAR_HASH: f605a051e4c8494addb65f3dcd512e7811c09486516b8da737fc287b98018a53fe46f963fccd4543342739c2f6bf39642aee4ca2e9f7868962ee78776c908e5a\nKUBE_MANIFESTS_TAR_URL: https://storage.googleapis.com/gke-release-eu/kubernetes/release/v1.27.7-gke.1056000/kubernetes-manifests.tar.gz,https://storage.googleapis.com/gke-release/kubernetes/release/v1.27.7-gke.1056000/kubernetes-manifests.tar.gz,https://storage.googleapis.com/gke-release-asia/kubernetes/release/v1.27.7-gke.1056000/kubernetes-manifests.tar.gz\nKUBE_PROXY_TOKEN: cVhPOiB3036JyivIGQ-XVM6tCkzSq0sWKIeTGso64cc=\nKUBELET_ARGS: --v=2 --cloud-provider=external --experimental-mounter-path=/home/kubernetes/containerized_mounter/mounter\n  --cert-dir=/var/lib/kubelet/pki/ --kubeconfig=/var/lib/kubelet/kubeconfig --max-pods=110\n  --volume-plugin-dir=/home/kubernetes/flexvolume --node-status-max-images=25 --container-runtime-endpoint=unix:///run/containerd/containerd.sock\n  --runtime-cgroups=/system.slice/containerd.service --registry-qps=10 --registry-burst=20\nKUBELET_VERSION: v1.27.7-gke.1056000\nKUBERNETES_MASTER: \"false\"\nKUBERNETES_MASTER_NAME: 172.16.0.34\nLOAD_IMAGE_COMMAND: ctr -n=k8s.io images import\nLOGGING_DESTINATION: \"\"\nLOGGING_STACKDRIVER_RESOURCE_TYPES: \"\"\nMONITORING_FLAG_SET: \"true\"\nNETWORK_PROVIDER: kubenet\nNODE_BFQ_IO_SCHEDULER_IO_WEIGHT: \"1200\"\nNODE_LOCAL_SSDS_EXT: \"\"\nNON_MASQUERADE_CIDR: 0.0.0.0/0\nREMOUNT_VOLUME_PLUGIN_DIR: \"true\"\nREQUIRE_METADATA_KUBELET_CONFIG_FILE: \"true\"\nSALT_TAR_HASH: \"\"\nSALT_TAR_URL: https://storage.googleapis.com/gke-release-eu/kubernetes/release/v1.27.7-gke.1056000/kubernetes-salt.tar.gz,https://storage.googleapis.com/gke-release/kubernetes/release/v1.27.7-gke.1056000/kubernetes-salt.tar.gz,https://storage.googleapis.com/gke-release-asia/kubernetes/release/v1.27.7-gke.1056000/kubernetes-salt.tar.gz\nSERVER_BINARY_TAR_HASH: 93ac70f0aa7a425318a854749b755ca07f00e80e3034e9461d6457dfbda1e2196f74eedd6591d0e869baebeaeac228be9eb0d84c33dc580f787418c1156fd6ac\nSERVER_BINARY_TAR_URL: https://storage.googleapis.com/gke-release-eu/kubernetes/release/v1.27.7-gke.1056000/kubernetes-server-linux-amd64.tar.gz,https://storage.googleapis.com/gke-release/kubernetes/release/v1.27.7-gke.1056000/kubernetes-server-linux-amd64.tar.gz,https://storage.googleapis.com/gke-release-asia/kubernetes/release/v1.27.7-gke.1056000/kubernetes-server-linux-amd64.tar.gz\nSERVICE_CLUSTER_IP_RANGE: 10.81.96.0/20\nSTACKDRIVER_ENDPOINT: https://logging.googleapis.com\nSTORAGE_ENDPOINT: https://storage.googleapis.com\nSYSCTL_OVERRIDES: \"\"\nTPM_BOOTSTRAP_CERT: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURxekNDQWhPZ0F3SUJBZ0lRYktyZmZmWWw4WDUyQTFMMUlNdHNBekFOQmdrcWhraUc5dzBCQVFzRkFEQXYKTVMwd0t3WURWUVFERXlRM1pXWTVNelF3WWkwNE5XWTBMVFJpT0RRdE9EWmhaaTFoTlRkallURXhZVEl6TURBdwpIaGNOTWpNeE1USTBNak0xTXpFeVdoY05Namd4TVRJeU1qTTFOVEV5V2pBY01Sb3dHQVlEVlFRREV4RnJkV0psCmJHVjBMV0p2YjNSemRISmhjRENDQVNJd0RRWUpLb1pJaHZjTkFRRUJCUUFEZ2dFUEFEQ0NBUW9DZ2dFQkFLdHUKRzZ1MFBhYWVPVDh0NXd0UG9LN1d5bmR0L2tmeVU5S2JhcFI3WjZseWFFOUw4WmdJMlZYYVdaekFlb01RQ0xUSwpVMTJ4Zm1BNzkySllqcGE4OXhGZjVLSUcrS0Mwai8rTWdmcThMZUJZVzhONkJBeWQrTlMwb3V2WG5FTmZZMWJYClQ2ZFY4SkdCZVpsRVA5L0hmWEdrd2pKZm8wQUs0NWdQRzh4RU5PRGE4OWdwT0loZUk0Qk8yWkZ0UmNPbmhBWGgKVnVZZng3M2lRYW9oaFBXSHZKK1hhajAxcS8vckVVRU9ZMDRGQ0JzOHNQcW14ZXc0dm15MjNuZVRxUzJnaVVqbgo2VGNidmhiREpKMmdOR3ZkMDZKTFpzN3NjL2gvR1A2c01XeCtsUE1rbG9yMi9uSlkyMXFFVmRKOWtDWW5RQlQ0CnRSeVFWT0FoQ011eFo3em5INGNDQXdFQUFhTldNRlF3RGdZRFZSMFBBUUgvQkFRREFnV2dNQk1HQTFVZEpRUU0KTUFvR0NDc0dBUVVGQndNQ01Bd0dBMVVkRXdFQi93UUNNQUF3SHdZRFZSMGpCQmd3Rm9BVUMyS3R3SU85NWdhMwppaUpNbGJHbTRld0lXU2t3RFFZSktvWklodmNOQVFFTEJRQURnZ0dCQUV5SFRtQ01CTWIrWDFpVUMveDRpTkVJCmNZWVFUUUFrNnQrRk9DSjYyRmJ3V0IxVTEvcnl4cnNpaHdpV0M4RVhGdXFlOVUwanZwZXhNRU9HdlVMNUVQck8KYmJtYU5LYVl2bXVqbmp3OVhvTTRYQkxqUjNBYlpNYk5oYmNWalgrSTZJV0lwMDVFbnRyb1hnWHY1QTd0UlhCUgpTYTZGcGVQL2pXV0ZCYnRBdmpYVmNidE1kY1RQaTVBM1p1dFFndWRVMXllYityTFcxWWxoVFVNSmRqeGJvTUlKCldHUEp2TU1Ydkl3eHE4UGtIZWtmOG9SUHQ5L3poOVY3MWdyQm84RTB5MlhGeWpwaCtqUUU1YnBQZWhUcHhkelcKQzRlcW5YcUNSVitXa1h5NENqNUJHRGJuWjlENWdnTWJ3d3hzVFhoWTUzMXIwMlYvWlZHdUpoVUZ5UE1vNmcxNgpIbFBKaGxPQWcxeU15SWlrK0VoVlZZZmJWbithd21lTUh5bDM0OElkOUJUbndmblpWZHlvbm9Vd2JKQ1k5NnloCjJjdVgyaVNQY2kxYlBod2V1Z1pHV1lEQm1taVhuemdVRmQ5SDB3dFlUWTFJUytmdVpxVER4VjQ1UFdYNkVIOFQKaVdMM2dydmRSL3NTVXNTdDlOcGlRN2VYYWVQclB3M3FCaXhTcncvSlhBPT0KLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo=\nTPM_BOOTSTRAP_KEY: LS0tLS1CRUdJTiBSU0EgUFJJVkFURSBLRVktLS0tLQpNSUlFb3dJQkFBS0NBUUVBcTI0YnE3UTlwcDQ1UHkzbkMwK2dydGJLZDIzK1IvSlQwcHRxbEh0bnFYSm9UMHZ4Cm1BalpWZHBabk1CNmd4QUl0TXBUWGJGK1lEdjNZbGlPbHJ6M0VWL2tvZ2I0b0xTUC80eUIrcnd0NEZoYnczb0UKREozNDFMU2k2OWVjUTE5alZ0ZFBwMVh3a1lGNW1VUS8zOGQ5Y2FUQ01sK2pRQXJqbUE4YnpFUTA0TnJ6MkNrNAppRjRqZ0U3WmtXMUZ3NmVFQmVGVzVoL0h2ZUpCcWlHRTlZZThuNWRxUFRXci8rc1JRUTVqVGdVSUd6eXcrcWJGCjdEaStiTGJlZDVPcExhQ0pTT2ZwTnh1K0ZzTWtuYUEwYTkzVG9rdG16dXh6K0g4WS9xd3hiSDZVOHlTV2l2YisKY2xqYldvUlYwbjJRSmlkQUZQaTFISkJVNENFSXk3Rm52T2NmaHdJREFRQUJBb0lCQUVyNUx0VGJVUk1ybzdIRAo2NFlBM3k5WDlOaGluSkR1cEVZNWZsVk4yem82TlBCcE1GSGpuTmwxVXpmQTNsT3ZrWDh2OVdIR25KU041VlYzCmtYVFBVK2FmWDZpVkQrdUl6R2xoRS8rS2lTM1N0dDg0MzhoODFqU0FnN2hOWmFQNWRjS25DOGtOUnRiOEh5Z3UKdHhpeGNHVmhQeVUwdW5ycHlEdmFiN2ZZSktBcHFQSEhLTytYdy9XcTQ2aVNQZXVvUDV3Q1hpTHNBWTJmUld1RApVaW0xNSthRU1qUlBqVjhEcHRzK1UrMEwwbWc3ODdYTEFLQXlIVXhweUoyQ1RDZjdtZE5kTTQxc0x5OU1ENGo4CkdMVG1SK0l3d1RMM3YzWmZzVVZLUzVVcCtJUE0vSWlBV1VCU1FsbHFoaGg2WHlkelJHR1JyQVJNVk1sRlBlcHgKYVVhVHJRRUNnWUVBOE5CMlYvS1Fma1pLMEZQVTZZWm9vVXo4MXEyV1hYajc1OERtTkVxUWIzOXY5U3hQQnJuVwpVTVo0dTdqOFhWYWtRcndzQS9wTjVWcnBzandJYmNPQjU5Nmo3b09MeFhQOFZRZnh1WldGQTZneUNiTHpqcHE3ClRzTlNZOHlIQlU5STRMM0NGR2xDT1FPekdkT0RBa1R3ZE1Ja3QvZnJTVVd4WGtCajdtN0VyTWNDZ1lFQXRqMk8KVGZsSE5hekh4V1o4UFN6OUREd0NpN2FkZlVMZnR1Kyt4a24zb0ZSVkNjWXBxL3crRzFMdmFGbjJRVHNMVkE4QwptdFRVUmV5WnFkcXBvM2RYT1RFS1BKZ0UrSTBZNHJtU2hzTFpZczlHWGZPSituck00cmE0R0o3Qm5kZnZOc2ViCmlwOEp0b0tBMm9HeTN5MXpmdGZOZEYwU2JsSGYrd0RyektmanQwRUNnWUF5aWUxc1E3SGpibWtoRTVicGM1WGQKMUVSejRYWmZJNWJxYW1kbHJnaGwvZjdIRzRkeVIrb2NoYXFzNndPN3F3VktKQ2V3cGdWWER4OWdrb3pLVEcrawo4K3Eva2NmeHBvZmNhSkJvZkdLd0E4cU1rb3ZlNzhaRG4yWlpINEZ1c2RiL281TnBxVFdHdGFvT3ozNzlLTzYxCjhsQzJjMGRqMTBhRUcwdGRyTTJGM1FLQmdFQmMyU2Q4eE1PV05DL3BsRE5lOGpnaDhadzZjTURPbjRoU2dBUTAKRjNyT2pnSVh0SndEU0VRS05IZWNYamFIamVhd0xuRlVmV3Y4dGdDaE00eUNGNUloV2NZd3dvQ3VCSDMrb0Z0cgo4YTdPR2NJUXcwaHRtbkx2cVhFNGtKVVlzR21lY2JheG1KS1c0TDlMVTBzekdEbFNLa1BRb3pQSFF0MjVZNDR5Ck5XQ0JBb0dCQU56eTBWMitoVy9kay8wLytERFZZeTNGUFdWVExLc2k1akpiaklQalF4SDNZSVJOZjN4NW5NRk8KeXhaSGlMYUN1NXBXZ3ZwM05TQUkrY2tXbGRMTWtra3JWWlNLcjJUaVFpeld0STA1K1U4SVZlVjhFMmU2dUNOdgpLRWtzSXVERUJKU3VPdXJpYnBXclNMYkNsZTRJRFBpRFl0SUQrdEJET2U1amg4bml2STd6Ci0tLS0tRU5EIFJTQSBQUklWQVRFIEtFWS0tLS0tCg==\nVOLUME_PLUGIN_DIR: /home/kubernetes/flexvolume\nZONE: europe-west1-b\n"
    kube-labels                = "cloud.google.com/gke-boot-disk=pd-balanced,cloud.google.com/gke-container-runtime=containerd,cloud.google.com/gke-cpu-scaling-level=2,cloud.google.com/gke-logging-variant=DEFAULT,cloud.google.com/gke-max-pods-per-node=110,cloud.google.com/gke-nodepool=default-pool,cloud.google.com/gke-os-distribution=cos,cloud.google.com/gke-provisioning=standard,cloud.google.com/gke-stack-type=IPV4,cloud.google.com/machine-family=e2"
    kubeconfig                 = "apiVersion: v1\nkind: Config\nclusters:\n- cluster:\n    server: https://172.16.0.34\n    certificate-authority: '/etc/srv/kubernetes/pki/ca-certificates.crt'\n  name: default-cluster\ncontexts:\n- context:\n    cluster: default-cluster\n    namespace: default\n    user: exec-plugin-auth\n  name: default-context\ncurrent-context: default-context\nusers:\n- name: exec-plugin-auth\n  user:\n    exec:\n      apiVersion: \"client.authentication.k8s.io/v1beta1\"\n      command: '/home/kubernetes/bin/gke-exec-auth-plugin'\n      args: [\"--cache-dir\", '/var/lib/kubelet/pki/']\n"
    kubelet-config             = "apiVersion: kubelet.config.k8s.io/v1beta1\nauthentication:\n  anonymous:\n    enabled: false\n  webhook:\n    enabled: true\n  x509:\n    clientCAFile: /etc/srv/kubernetes/pki/ca-certificates.crt\nauthorization:\n  mode: Webhook\ncgroupRoot: /\nclusterDNS:\n- 10.81.96.10\nclusterDomain: cluster.local\nenableDebuggingHandlers: true\nevictionHard:\n  memory.available: 100Mi\n  nodefs.available: 10%\n  nodefs.inodesFree: 5%\n  pid.available: 10%\nfeatureGates:\n  CSIMigrationGCE: true\n  ExecProbeTimeout: false\n  InTreePluginAWSUnregister: true\n  InTreePluginAzureDiskUnregister: true\n  InTreePluginvSphereUnregister: true\n  RotateKubeletServerCertificate: true\nkernelMemcgNotification: true\nkind: KubeletConfiguration\nkubeReserved:\n  cpu: 70m\n  ephemeral-storage: 41Gi\n  memory: 2623Mi\nmaxParallelImagePulls: 3\nreadOnlyPort: 10255\nserializeImagePulls: false\nserverTLSBootstrap: true\nstaticPodPath: /etc/kubernetes/manifests\n"
    serial-port-logging-enable = "true"
    user-data                  = "#cloud-config\n\nusers:\n  - name: kube-bootstrap-logs-forwarder\n    gecos: User the kube-bootstrap-logs-forwarder.service runs as.\n    system: true\n\nwrite_files:\n  - path: /etc/systemd/system/kube-bootstrap-logs-forwarder.service\n    permissions: '0644'\n    owner: root\n    content: |\n      [Unit]\n      Description=Forwards Kubernetes bootstrap logs to serial port.\n      Before=kube-node-installation.service\n\n      [Service]\n      User=kube-bootstrap-logs-forwarder\n      Group=systemd-journal\n      SupplementaryGroups=serial\n      ExecStart=journalctl --no-tail --no-pager --follow --utc --output short-iso --unit kube-node-installation --unit kube-node-configuration --unit kubelet\n      StandardOutput=tty\n      TTYPath=/dev/ttyS2\n\n      [Install]\n      WantedBy=kubernetes.target\n\n  - path: /etc/systemd/system/kube-node-installation.service\n    permissions: '0644'\n    owner: root\n    content: |\n      [Unit]\n      Description=Download and install k8s binaries and configurations\n      After=network-online.target\n\n      [Service]\n      Type=oneshot\n      RemainAfterExit=yes\n      ExecStartPre=/bin/mkdir -p /home/kubernetes/bin\n      ExecStartPre=/bin/mount --bind /home/kubernetes/bin /home/kubernetes/bin\n      ExecStartPre=/bin/mount -o remount,exec /home/kubernetes/bin\n      ExecStartPre=/usr/bin/curl --fail --retry 5 --retry-delay 3 --silent --show-error -H \"X-Google-Metadata-Request: True\" -o /home/kubernetes/bin/configure.sh http://metadata.google.internal/computeMetadata/v1/instance/attributes/configure-sh\n      ExecStartPre=/bin/chmod 544 /home/kubernetes/bin/configure.sh\n      ExecStart=/home/kubernetes/bin/configure.sh\n\n      [Install]\n      WantedBy=kubernetes.target\n\n  - path: /etc/systemd/system/kube-node-configuration.service\n    permissions: '0644'\n    owner: root\n    content: |\n      [Unit]\n      Description=Configure kubernetes node\n      After=kube-node-installation.service\n\n      [Service]\n      Type=oneshot\n      RemainAfterExit=yes\n      ExecStartPre=/bin/chmod 544 /home/kubernetes/bin/configure-helper.sh\n      ExecStart=/home/kubernetes/bin/configure-helper.sh\n      ExecStartPost=systemctl stop kube-bootstrap-logs-forwarder.service\n\n      [Install]\n      WantedBy=kubernetes.target\n\n  - path: /etc/systemd/system/kube-container-runtime-monitor.service\n    permissions: '0644'\n    owner: root\n    content: |\n      [Unit]\n      Description=Kubernetes health monitoring for container runtime\n      After=kube-node-configuration.service\n\n      [Service]\n      Restart=always\n      RestartSec=10\n      RemainAfterExit=yes\n      RemainAfterExit=yes\n      ExecStartPre=/bin/chmod 544 /home/kubernetes/bin/health-monitor.sh\n      ExecStart=/home/kubernetes/bin/health-monitor.sh container-runtime\n\n      [Install]\n      WantedBy=kubernetes.target\n\n  - path: /etc/systemd/system/kubelet-monitor.service\n    permissions: '0644'\n    owner: root\n    content: |\n      [Unit]\n      Description=Kubernetes health monitoring for kubelet\n      After=kube-node-configuration.service\n\n      [Service]\n      Restart=always\n      RestartSec=10\n      RemainAfterExit=yes\n      RemainAfterExit=yes\n      ExecStartPre=/bin/chmod 544 /home/kubernetes/bin/health-monitor.sh\n      ExecStart=/home/kubernetes/bin/health-monitor.sh kubelet\n\n      [Install]\n      WantedBy=kubernetes.target\n\n  - path: /etc/systemd/system/kube-logrotate.timer\n    permissions: '0644'\n    owner: root\n    content: |\n      [Unit]\n      Description=Hourly kube-logrotate invocation\n\n      [Timer]\n      OnCalendar=hourly\n\n      [Install]\n      WantedBy=kubernetes.target\n\n  - path: /etc/systemd/system/kube-logrotate.service\n    permissions: '0644'\n    owner: root\n    content: |\n      [Unit]\n      Description=Kubernetes log rotation\n      After=kube-node-configuration.service\n\n      [Service]\n      Type=oneshot\n      ExecStart=-/usr/sbin/logrotate /etc/logrotate.conf\n\n      [Install]\n      WantedBy=kubernetes.target\n\n  - path: /etc/systemd/system/kubernetes.target\n    permissions: '0644'\n    owner: root\n    content: |\n      [Unit]\n      Description=Kubernetes\n\n      [Install]\n      WantedBy=multi-user.target\n\n  - path: /etc/modprobe.d/sunrpc.conf\n    permissions: '0644'\n    owner: root\n    # The GKE metadata server uses ports 987-989, so the sunrpc range should be restricted to be below.\n    content: |\n      options sunrpc max_resvport=986\n\nruncmd:\n - systemctl daemon-reload\n - systemctl enable kube-bootstrap-logs-forwarder.service\n - systemctl enable kube-node-installation.service\n - systemctl enable kube-node-configuration.service\n - systemctl enable kube-container-runtime-monitor.service\n - systemctl enable kubelet-monitor.service\n - systemctl enable kube-logrotate.timer\n - systemctl enable kube-logrotate.service\n - systemctl enable kubernetes.target\n - systemctl start kubernetes.target\n"
  }

  name = "gke-private-cluster-3-default-pool-bfffbc48"

  network_interface {
    alias_ip_range {
      ip_cidr_range         = "/24"
      subnetwork_range_name = "gke-private-cluster-3-pods-cfa1fee5"
    }

    network            = "https://www.googleapis.com/compute/v1/projects/vaulted-gift-406223/global/networks/default"
    stack_type         = "IPV4_ONLY"
    subnetwork         = "https://www.googleapis.com/compute/v1/projects/vaulted-gift-406223/regions/europe-west1/subnetworks/k8s-subnet-dersalvador"
    subnetwork_project = "vaulted-gift-406223"
  }

  project = "vaulted-gift-406223"
  region  = "europe-west1"

  scheduling {
    automatic_restart   = "true"
    min_node_cpus       = "0"
    on_host_maintenance = "MIGRATE"
    preemptible         = "false"
  }

  service_account {
    email  = "default"
    scopes = ["https://www.googleapis.com/auth/devstorage.read_only", "https://www.googleapis.com/auth/logging.write", "https://www.googleapis.com/auth/monitoring", "https://www.googleapis.com/auth/service.management.readonly", "https://www.googleapis.com/auth/servicecontrol", "https://www.googleapis.com/auth/trace.append"]
  }

  shielded_instance_config {
    enable_integrity_monitoring = "true"
    enable_secure_boot          = "false"
    enable_vtpm                 = "true"
  }

  tags = ["gke-private-cluster-3-cfa1fee5-node"]
}
